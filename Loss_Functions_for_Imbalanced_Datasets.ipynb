{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wqcRMp1IHu0F"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, Model\n",
        "# from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.metrics import balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "# import os\n",
        "\n",
        "\n",
        "# BATCH_SIZE = 32\n",
        "# # Define the number of training epochs\n",
        "# NUM_EPOCHS = 200 # You can adjust this number\n",
        "\n",
        "# # Parameters for AMRL\n",
        "# M_POS = 2.0\n",
        "# M_NEG = -2.0\n",
        "# LAMBDA_POS = 10.0\n",
        "# LAMBDA_NEG = 1.0\n",
        "# BETA_POS = 2\n",
        "# BETA_NEG = 1\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Define your Google Drive base path (adjust as needed)\n",
        "# GOOGLE_DRIVE_PATH = '/content/drive/MyDrive/converted_excel_files_all/'\n",
        "\n",
        "# results_file_path = '/content/drive/MyDrive//imbalanced_loss_comparison_summary.xlsx'\n",
        "\n",
        "# # --- 5. Neural Network Model (TensorFlow/Keras) ---\n",
        "# class SimpleMLP_TF(Model):\n",
        "#     def __init__(self, input_dim):\n",
        "#         super(SimpleMLP_TF, self).__init__()\n",
        "#         #self.fc1 = layers.Dense(128, activation='relu')\n",
        "#         self.fc1 = layers.Dense(128, activation='relu', input_shape=(input_dim,))\n",
        "#         self.fc2 = layers.Dense(64, activation='relu')\n",
        "#         self.fc3 = layers.Dense(1) # Output a single logit for binary classification\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         x = self.fc1(inputs)\n",
        "#         x = self.fc2(x)\n",
        "#         return self.fc3(x)\n",
        "\n",
        "\n",
        "# # --- 2. Data Loading from Google Drive ---\n",
        "# # This function is now the sole method for loading data.\n",
        "# def load_data_from_drive(file_path):\n",
        "#     \"\"\"\n",
        "#     Loads a dataset from a given file path.\n",
        "#     Assumes the last column is the target and no header row in the CSV file.\n",
        "#     Args:\n",
        "#         file_path (str): The full path to the CSV file.\n",
        "#     Returns:\n",
        "#         pd.DataFrame: Loaded DataFrame.\n",
        "#     \"\"\"\n",
        "#     if not os.path.exists(file_path):\n",
        "#         print(f\"Error: File not found at {file_path}.\")\n",
        "#         return None\n",
        "\n",
        "#     # Read CSV assuming no header. Pandas will assign integer column names (0, 1, 2, ...)\n",
        "#     print(f\"Attempting to read Excel file: {file_path}\")\n",
        "#     try:\n",
        "#         df = pd.read_excel(file_path, header=None)\n",
        "#         print(f\"Loaded {os.path.basename(file_path)} with shape: {df.shape}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error reading Excel file {file_path}: {e}\")\n",
        "#         # Attempt to read as CSV as a fallback\n",
        "#         try:\n",
        "#             df = pd.read_csv(file_path, header=None)\n",
        "#             print(f\"Loaded {os.path.basename(file_path)} as CSV with shape: {df.shape}\")\n",
        "#         except Exception as e_csv:\n",
        "#             print(f\"Error reading CSV file {file_path}: {e_csv}\")\n",
        "#             print(f\"Failed to load {file_path} as both Excel and CSV.\")\n",
        "#             return None\n",
        "\n",
        "\n",
        "#     # The last column will be identified by its index (e.g., df.columns[-1] will be the last integer index).\n",
        "#     print(f\"Assuming the last column '{df.columns[-1]}' is the target column (no header specified).\")\n",
        "#     print(f\"Class distribution of the last column:\\n{df.iloc[:, -1].value_counts()}\")\n",
        "#     return df\n",
        "\n",
        "\n",
        "# # --- Loss Function Implementations for TensorFlow ---\n",
        "\n",
        "# class AMRLLossTF(tf.keras.losses.Loss):\n",
        "#   \"\"\"\n",
        "#   Margin Loss for Imbalanced Datasets in TensorFlow.\n",
        "#   Combines Weighted Binary Cross-Entropy with an Asymmetric Margin Penalty.\n",
        "#   \"\"\"\n",
        "#   def __init__(self, w1, w0, m1, m0, lambda1, lambda0, beta1=1, beta0=1, name=\"margin_loss_tf\"):\n",
        "#     super().__init__(name=name)\n",
        "#     self.w1 = tf.constant(w1, dtype=tf.float32)\n",
        "#     self.w0 = tf.constant(w0, dtype=tf.float32)\n",
        "#     # These are now trainable variables!\n",
        "#     self.m1 = tf.Variable(m1, dtype=tf.float32, trainable=True, name=\"m1\")\n",
        "#     self.m0 = tf.Variable(m0, dtype=tf.float32, trainable=True, name=\"m0\")\n",
        "#     self.lambda1 = tf.Variable(lambda1, dtype=tf.float32, trainable=True, name=\"lambda1\")\n",
        "#     self.lambda0 = tf.Variable(lambda0, dtype=tf.float32, trainable=True, name=\"lambda0\")\n",
        "#     self.beta1 = tf.constant(float(beta1), dtype=tf.float32)\n",
        "#     self.beta0 = tf.constant(float(beta0), dtype=tf.float32)\n",
        "\n",
        "#   def call(self, y_true, y_pred_logits):\n",
        "#     y_true = tf.cast(y_true, tf.float32)\n",
        "#     y_pred_logits = tf.cast(y_pred_logits, tf.float32)\n",
        "\n",
        "#     bce_unweighted = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred_logits)\n",
        "#     l_w_bce = tf.where(tf.equal(y_true, 1), bce_unweighted * self.w1, bce_unweighted * self.w0)\n",
        "\n",
        "#     l_amp = tf.zeros_like(y_pred_logits)\n",
        "#     penalty_minority = self.lambda1 * tf.pow(tf.maximum(0., self.m1 - y_pred_logits), self.beta1)\n",
        "#     l_amp = tf.where(tf.equal(y_true, 1), penalty_minority, l_amp)\n",
        "\n",
        "#     penalty_majority = self.lambda0 * tf.pow(tf.maximum(0., y_pred_logits - self.m0), self.beta0)\n",
        "#     l_amp = tf.where(tf.equal(y_true, 0), penalty_majority, l_amp)\n",
        "\n",
        "#     total_loss = tf.reduce_mean(l_w_bce + l_amp)\n",
        "\n",
        "#     return total_loss\n",
        "\n",
        "#   @property\n",
        "#   def trainable_variables(self):\n",
        "#       # Expose trainable variables for optimizer\n",
        "#     return [self.m1, self.m0, self.lambda1, self.lambda0]\n",
        "\n",
        "# class FocalLossTF(tf.keras.losses.Loss):\n",
        "#   \"\"\"\n",
        "#   Focal Loss for Imbalanced Datasets in TensorFlow.\n",
        "#   Focuses training on hard, misclassified examples by down-weighting easy examples.\n",
        "#   \"\"\"\n",
        "#   def __init__(self, alpha=0.25, gamma=2.0, name=\"focal_loss_tf\"):\n",
        "#     super().__init__(name=name)\n",
        "#     self.alpha = tf.constant(alpha, dtype=tf.float32)\n",
        "#     self.gamma = tf.constant(gamma, dtype=tf.float32)\n",
        "\n",
        "#   def call(self, y_true, y_pred_logits):\n",
        "#     y_true = tf.cast(y_true, tf.float32)\n",
        "#     y_pred_logits = tf.cast(y_pred_logits, tf.float32)\n",
        "\n",
        "#     # Calculate standard BCE (log loss)\n",
        "#     bce = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred_logits)\n",
        "\n",
        "#     # Calculate probabilities\n",
        "#     p = tf.sigmoid(y_pred_logits)\n",
        "\n",
        "#     # p_t is the probability of the true class\n",
        "#     p_t = y_true * p + (1 - y_true) * (1 - p)\n",
        "\n",
        "#     # alpha_t is alpha for positive, 1-alpha for negative\n",
        "#     alpha_t = y_true * self.alpha + (1 - y_true) * (1.0 - self.alpha)\n",
        "\n",
        "#     # Modulating factor (1 - p_t)^gamma\n",
        "#     modulating_factor = tf.pow(1.0 - p_t, self.gamma)\n",
        "\n",
        "#     # Focal Loss: alpha_t * (1 - p_t)^gamma * BCE\n",
        "#     focal_loss = alpha_t * modulating_factor * bce\n",
        "#     return tf.reduce_mean(focal_loss)\n",
        "\n",
        "# class ClassBalancedLossTF(tf.keras.losses.Loss):\n",
        "#   \"\"\"\n",
        "#   Class Balanced Loss for Imbalanced Datasets in TensorFlow.\n",
        "#   Re-weights the standard loss by the 'effective number of samples' for each class.\n",
        "#   \"\"\"\n",
        "#   def __init__(self, num_majority, num_minority, beta=0.999, name=\"class_balanced_loss_tf\"):\n",
        "#     super().__init__(name=name)\n",
        "#     self.beta = tf.constant(beta, dtype=tf.float32)\n",
        "\n",
        "#     # Calculate effective number of samples for each class\n",
        "#     # Add a small epsilon to avoid division by zero in case num_samples is 0 or beta is 1\n",
        "#     epsilon = tf.keras.backend.epsilon()\n",
        "\n",
        "#     effective_num_majority = (1.0 - tf.pow(self.beta, tf.cast(num_majority, tf.float32))) / (1.0 - self.beta + epsilon)\n",
        "#     effective_num_minority = (1.0 - tf.pow(self.beta, tf.cast(num_minority, tf.float32))) / (1.0 - self.beta + epsilon)\n",
        "\n",
        "#     # Calculate class-balanced weights\n",
        "#     self.w0_cb = tf.constant(1.0, dtype=tf.float32) / effective_num_majority\n",
        "#     self.w1_cb = tf.constant(1.0, dtype=tf.float32) / effective_num_minority\n",
        "\n",
        "#     tf.print(f\"CB Loss Weights: w0 (majority)={self.w0_cb}, w1 (minority)={self.w1_cb}\")\n",
        "\n",
        "#   def call(self, y_true, y_pred_logits):\n",
        "#     y_true = tf.cast(y_true, tf.float32)\n",
        "#     y_pred_logits = tf.cast(y_pred_logits, tf.float32)\n",
        "\n",
        "#     # Calculate standard BCE\n",
        "#     bce_unweighted = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred_logits)\n",
        "\n",
        "#     # Apply class-balanced weights\n",
        "#     cb_loss = tf.where(tf.equal(y_true, 1), bce_unweighted * self.w1_cb, bce_unweighted * self.w0_cb)\n",
        "\n",
        "#     return tf.reduce_mean(cb_loss)\n",
        "\n",
        "\n",
        "# # --- 6. Main Execution Block ---\n",
        "# if __name__ == \"__main__\":\n",
        "#     # List of loss functions to compare\n",
        "#     LOSS_TYPES_TO_COMPARE = ['AMRL', 'BCE', 'FOCAL', 'CB']\n",
        "\n",
        "\n",
        "#     all_test_results = [] # To store results from all loss functions - This will no longer be used for saving all results\n",
        "\n",
        "#     # --- Configuration for data loading ---\n",
        "#     # This script is now configured to ONLY load from Google Drive.\n",
        "#     # Please uncomment and configure GOOGLE_DRIVE_PATH\n",
        "\n",
        "#     # Ensure GOOGLE_DRIVE_PATH is set and exists\n",
        "#     if 'GOOGLE_DRIVE_PATH' not in globals() or not os.path.exists(GOOGLE_DRIVE_PATH):\n",
        "#         raise ValueError(\"GOOGLE_DRIVE_PATH not set or does not exist. Please configure it to your Google Drive folder containing CSV files.\")\n",
        "\n",
        "#     print(f\"Scanning for XLSX files in: {GOOGLE_DRIVE_PATH}\")\n",
        "\n",
        "\n",
        "#     file_paths_to_process = [os.path.join(GOOGLE_DRIVE_PATH, f) for f in os.listdir(GOOGLE_DRIVE_PATH) if f.endswith('.xlsx')]\n",
        "#     # sort the files\n",
        "#     file_paths_to_process = sorted(file_paths_to_process, key=lambda x: os.path.basename(x).lower())\n",
        "\n",
        "#     if not file_paths_to_process:\n",
        "#         print(f\"No XLSX files found in {GOOGLE_DRIVE_PATH}. Please check the path and file extensions.\")\n",
        "#         exit()\n",
        "\n",
        "#     for file_path in file_paths_to_process:\n",
        "#         current_file_name = os.path.basename(file_path)\n",
        "#         print(f\"\\n############################################################\")\n",
        "#         print(f\"Processing Dataset: {current_file_name}\")\n",
        "#         print(f\"############################################################\")\n",
        "\n",
        "#         # Load data for the current file\n",
        "#         df = load_data_from_drive(file_path)\n",
        "#         if df is None:\n",
        "#             print(f\"Skipping {current_file_name} due to loading error.\")\n",
        "#             continue # Skip to the next file\n",
        "\n",
        "#         # Define features (X) and target (y)\n",
        "#         # Assumes the last column is always the target\n",
        "#         X = df.iloc[:, :-1]\n",
        "#         y = df.iloc[:, -1]\n",
        "\n",
        "#         # --- Data Preprocessing and Splitting (for current dataset) ---\n",
        "#         print(\"\\nSplitting data into train, validation, and test sets...\")\n",
        "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify = y)\n",
        "#         X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = (0.1/0.8), random_state=42, stratify = y_train)\n",
        "\n",
        "#         print(f\"Train set size: {len(X_train)} (Minority: {y_train.sum()})\")\n",
        "#         print(f\"Validation set size: {len(X_val)} (Minority: {y_val.sum()})\")\n",
        "#         print(f\"Test set size: {len(X_test)} (Minority: {y_test.sum()})\")\n",
        "\n",
        "#         scaler = StandardScaler()\n",
        "#         X_train_scaled = scaler.fit_transform(X_train)\n",
        "#         X_val_scaled = scaler.transform(X_val)\n",
        "#         X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#         y_train_tf = y_train.values.astype(np.float32).reshape(-1, 1)\n",
        "#         y_val_tf = y_val.values.astype(np.float32).reshape(-1, 1)\n",
        "#         y_test_tf = y_test.values.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "\n",
        "#         train_dataset_tf = tf.data.Dataset.from_tensor_slices((X_train_scaled.astype(np.float32), y_train_tf)).batch(BATCH_SIZE).shuffle(buffer_size=len(X_train_scaled))\n",
        "#         val_dataset_tf = tf.data.Dataset.from_tensor_slices((X_val_scaled.astype(np.float32), y_val_tf)).batch(BATCH_SIZE)\n",
        "#         test_dataset_tf = tf.data.Dataset.from_tensor_slices((X_test_scaled.astype(np.float32), y_test_tf)).batch(BATCH_SIZE)\n",
        "\n",
        "#         # --- Loss Function Parameters (common calculations for current dataset) ---\n",
        "#         num_minority = np.sum(y_train)\n",
        "#         num_majority = len(y_train) - num_minority\n",
        "\n",
        "\n",
        "#         w1_bce_amrl = num_majority / (num_minority + num_majority)\n",
        "#         w0_bce_amrl = num_minority / (num_minority + num_majority)\n",
        "\n",
        "#         # Parameters for Focal Loss\n",
        "#         alpha_focal = num_majority / (num_minority + num_majority)\n",
        "#         gamma_focal = 2.0\n",
        "\n",
        "#         # Parameters for Class Balanced Loss\n",
        "#         beta_cb = 0.999\n",
        "\n",
        "#         # Calculate input_dim from the scaled training data shape\n",
        "#         input_dim = X_train_scaled.shape[1]\n",
        "#         print(f\"Input dimension for the model: {input_dim}\")\n",
        "\n",
        "#         loss_results_for_file = [] # List to store results for each loss function for the current file\n",
        "\n",
        "#         for loss_type in LOSS_TYPES_TO_COMPARE:\n",
        "#             print(f\"\\n--------------------------------------------------------\")\n",
        "#             print(f\"Training {current_file_name} with {loss_type} Loss\")\n",
        "#             print(f\"--------------------------------------------------------\")\n",
        "\n",
        "#             # Re-initialize the model for each loss function to ensure a fresh start\n",
        "#             model = SimpleMLP_TF(input_dim)\n",
        "\n",
        "#             loss_function = None\n",
        "\n",
        "\n",
        "#             if loss_type == 'AMRL':\n",
        "#                 print(\"Margin Loss Parameters:\")\n",
        "#                 print(f\"  BCE Weights: w1_bce (minority) = {w1_bce_amrl:.4f}, w0_bce (majority) = {w0_bce_amrl:.4f}\")\n",
        "#                 print(f\"  Margins: m1 (pos) = {M_POS}, m0 (neg) = {M_NEG}\")\n",
        "#                 print(f\"  Lambdas: lambda1 (pos) = {LAMBDA_POS}, lambda0 (neg) = {LAMBDA_NEG}\")\n",
        "#                 print(f\"  Betas: beta1 (pos) = {BETA_POS}, beta0 (neg) = {BETA_NEG}\")\n",
        "#                 loss_function = AMRLLossTF(w1 = w1_bce_amrl, w0 = w0_bce_amrl, m1 = M_POS, m0 = M_NEG,\n",
        "#                                           lambda1=LAMBDA_POS, lambda0 = LAMBDA_NEG,\n",
        "#                                           beta1 = BETA_POS, beta0 = BETA_NEG)\n",
        "#             elif loss_type == 'BCE':\n",
        "#                 print(\"Standard Binary Crossentropy Loss\")\n",
        "#                 loss_function = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
        "#             elif loss_type == 'FOCAL':\n",
        "#                 print(f\"Focal Loss Parameters: alpha={alpha_focal:.4f}, gamma={gamma_focal:.4f}\")\n",
        "#                 loss_function = FocalLossTF(alpha = alpha_focal, gamma = gamma_focal)\n",
        "#             elif loss_type == 'CB':\n",
        "#                 print(f\"Class Balanced Loss Parameters: beta={beta_cb:.4f}\")\n",
        "#                 loss_function = ClassBalancedLossTF(num_majority = num_majority, num_minority = num_minority, beta = beta_cb)\n",
        "#             else:\n",
        "#                 raise ValueError(f\"Invalid LOSS_TYPE: {loss_type}. Choose from 'AMRL', 'BCE', 'FOCAL', 'CB'.\")\n",
        "\n",
        "\n",
        "#             # Compile the model with the selected loss and relevant metrics\n",
        "#             model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "#                           loss=loss_function,\n",
        "#                           metrics=[\n",
        "#                               BinaryAccuracy(name = 'accuracy', threshold = 0.5),\n",
        "#                               Precision(name = 'precision', thresholds = 0.5),\n",
        "#                               Recall(name = 'recall', thresholds = 0.5),\n",
        "#                               AUC(name = 'auc_roc'), # ROC AUC\n",
        "#                               AUC(curve = 'PR', name =' auc_pr') # Precision-Recall AUC\n",
        "#                           ])\n",
        "\n",
        "\n",
        "#             reduce_lr = ReduceLROnPlateau(\n",
        "#                                           monitor = 'val_loss',     # metric to monitor\n",
        "#                                           factor = 0.5,             # reduce LR by this factor\n",
        "#                                           patience = 3,             # wait 3 epochs with no improvement\n",
        "#                                           min_lr = 1e-6,            # lower bound on LR\n",
        "#                                           verbose = 1\n",
        "#                                           )\n",
        "\n",
        "#             print(\"\\nStarting training...\")\n",
        "#             history = model.fit(train_dataset_tf,\n",
        "#                                 epochs = NUM_EPOCHS,\n",
        "#                                 validation_data = val_dataset_tf,\n",
        "#                                 verbose = 0,\n",
        "#                                 callbacks = [reduce_lr]) # Set verbose to 0 to reduce output during batch runs\n",
        "\n",
        "#             print(\"Training finished.\")\n",
        "\n",
        "#             print(\"\\nEvaluating on the Test Set...\")\n",
        "#             # Get raw logits and true labels for full metric calculation\n",
        "#             y_pred_logits_test = model.predict(X_test_scaled.astype(np.float32))\n",
        "#             y_pred_probs_test = tf.sigmoid(y_pred_logits_test).numpy().flatten()\n",
        "#             y_pred_binary_test = (y_pred_probs_test > 0.5).astype(int)\n",
        "#             y_true_test_flat = y_test.values.flatten()\n",
        "\n",
        "#             # Calculate additional metrics\n",
        "#             # Confusion Matrix components\n",
        "#             tn, fp, fn, tp = confusion_matrix(y_true_test_flat, y_pred_binary_test, labels=[0, 1]).ravel()\n",
        "\n",
        "#             # Specificity (True Negative Rate)\n",
        "#             specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "#             # Geometric Mean (G-mean)\n",
        "#             # Recall is already available from Keras metrics\n",
        "#             #current_recall = model.evaluate(test_dataset_tf, verbose=0)[3] # Index 3 is 'recall'\n",
        "#             current_recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "#             g_mean = np.sqrt(current_recall * specificity) if current_recall >= 0 and specificity >= 0 else np.nan\n",
        "\n",
        "#             # Balanced Accuracy\n",
        "#             bal_accuracy = balanced_accuracy_score(y_true_test_flat, y_pred_binary_test)\n",
        "\n",
        "#             # Kuipers Skill Score (KSS) / True Skill Score (TSS)\n",
        "#             kss_tss = current_recall + specificity - 1\n",
        "\n",
        "#             # Heidke Skill Score (HSS)\n",
        "#             # Expected Accuracy (chance accuracy)\n",
        "#             total_samples = len(y_true_test_flat)\n",
        "#             p_pos_true = np.sum(y_true_test_flat == 1) / total_samples\n",
        "#             p_neg_true = np.sum(y_true_test_flat == 0) / total_samples\n",
        "#             p_pos_pred = np.sum(y_pred_binary_test == 1) / total_samples\n",
        "#             p_neg_pred = np.sum(y_pred_binary_test == 0) / total_samples\n",
        "\n",
        "#             expected_accuracy = (p_pos_true * p_pos_pred) + (p_neg_true * p_neg_pred)\n",
        "\n",
        "#             current_accuracy = accuracy_score(y_true_test_flat, y_pred_binary_test) # Recalculate accuracy for consistency\n",
        "#             hss = (current_accuracy - expected_accuracy) / (1 - expected_accuracy) if (1 - expected_accuracy) != 0 else np.nan\n",
        "\n",
        "\n",
        "#             print(f\"\\n--- Test Set Results for {loss_type} on {current_file_name} ---\")\n",
        "#             # Get standard Keras metrics from the last evaluation\n",
        "#             keras_metrics = model.evaluate(test_dataset_tf, verbose=0)\n",
        "#             metric_names = ['Loss', 'Accuracy', 'Precision', 'Recall', 'AUC-ROC', 'AUC-PR']\n",
        "#             test_metrics_dict = dict(zip(metric_names, keras_metrics))\n",
        "\n",
        "#             # Add new metrics\n",
        "#             test_metrics_dict['Specificity'] = specificity\n",
        "#             test_metrics_dict['G-Mean'] = g_mean\n",
        "#             test_metrics_dict['Balanced_Accuracy'] = bal_accuracy\n",
        "#             test_metrics_dict['KSS_TSS'] = kss_tss\n",
        "#             test_metrics_dict['HSS'] = hss\n",
        "\n",
        "#             # Add dataset name and loss type\n",
        "#             test_metrics_dict['Dataset'] = current_file_name\n",
        "#             test_metrics_dict['Loss_Type'] = loss_type\n",
        "#             #all_test_results.append(test_metrics_dict) # No longer appending to the overall list\n",
        "\n",
        "#             for metric, value in test_metrics_dict.items():\n",
        "#                 if isinstance(value, float):\n",
        "#                     print(f\"{metric}: {value:.4f}\")\n",
        "#                 else:\n",
        "#                     print(f\"{metric}: {value}\")\n",
        "\n",
        "#             # --- Consolidate and Save All Results ---\n",
        "#             #results_df = pd.DataFrame(all_test_results) # This will now be done per file\n",
        "\n",
        "#             # Define the path to save the results file\n",
        "#             base_path = globals().get('GOOGLE_DRIVE_PATH', './') # Defaults to current directory if GOOGLE_DRIVE_PATH not set\n",
        "\n",
        "#             # Save this loss result in the list\n",
        "#             loss_results_for_file.append(test_metrics_dict.copy())\n",
        "\n",
        "#         # --- Save all loss results for the current file ---\n",
        "#         file_results_df = pd.DataFrame(loss_results_for_file)\n",
        "#         output_filename = f\"{current_file_name}_all_losses.csv\"\n",
        "#         output_filepath = os.path.join(base_path, output_filename)\n",
        "#         file_results_df.to_csv(output_filepath, index=False)\n",
        "\n",
        "#         print(f\"\\nResults for {current_file_name} saved to: {output_filepath}\")\n",
        "#         print(\"\\nComprehensive Comparison Summary for this file:\")\n",
        "#         print(file_results_df.round(4).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Import EarlyStopping callback\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau # Keep import in case it's used elsewhere, but not needed for custom loop LR reduction\n",
        "from google.colab import drive # Import drive here\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
        "\n",
        "import matplotlib.pyplot as plt # Import matplotlib for plotting\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import save_model"
      ],
      "metadata": {
        "id": "eVq3ufYpeyuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define your Google Drive base path (adjust as needed)\n",
        "GOOGLE_DRIVE_PATH = '/content/drive/MyDrive/1. Trial/'\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 5\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Parameters for AMRL (initial values â€“ these will be trained)\n",
        "M_POS_INIT = 1.0\n",
        "M_NEG_INIT = -1.0\n",
        "LAMBDA_POS_INIT = 2.0\n",
        "LAMBDA_NEG_INIT = 1.0\n",
        "BETA_POS_INIT = 2\n",
        "BETA_NEG_INIT = 1\n",
        "\n",
        "# Early stopping parameters\n",
        "EARLY_STOPPING_PATIENCE = 20  # Number of epochs with no improvement before stopping\n",
        "MIN_DELTA = 0.0001            # Minimum improvement to be considered as progress\n",
        "\n",
        "# Gradient clipping parameter\n",
        "CLIP_NORM = 1.0  # Maximum L2 norm of the gradients\n",
        "\n",
        "# GAN training stability parameters\n",
        "ADD_NOISE = True           # Add noise to discriminator inputs\n",
        "NOISE_STDDEV = 0.1         # Standard deviation of the noise\n",
        "DISC_TRAIN_RATIO = 1       # Number of discriminator steps per generator step\n",
        "GAN_LAMBDA = 0.1           # Weighting factor for adversarial loss in generator\n",
        "\n"
      ],
      "metadata": {
        "id": "_biKzV-Her6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#FALSE_ALARM_RATE(FAR)=Ratio of the number of false prediction of danger and the total number of the model prediction when actually no danger was observed.\n",
        "                                  #FAR=b/(b+d);0=<FAR<=1\"\"\"\n",
        "def false_alarm(tp,tn,fp,fn):\n",
        "\n",
        "    false_alarm = fp / (fp + tn)\n",
        "    false_alarm = round(false_alarm, 2)\n",
        "\n",
        "#print('The false alarm value of model is:',false_alarm)\n",
        "    return false_alarm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"#BIAS_SCORE=Ratio of the number of days whe the model predicted 'danger and the total number of avalanche occurences events.\n",
        "                                  #B=(a+b)/(a+c)\n",
        "                                  #B=1 -> Unbiased\n",
        "                                  #B<=1 -> Underforcast\n",
        "                                  #B>=1 -> Overforecast\"\"\"\n",
        "def bias_score(tp,tn,fp,fn):\n",
        "\n",
        "    bias_score = (tp + fp) / (tp + fn)\n",
        "    bias_score = round(bias_score, 2)\n",
        "    #print('The bias score of model is:',bias_score)\n",
        "    return bias_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"#Probability of detection(PoD)=Probability that the event was forecast when it occurred.\n",
        "                                  #PoD=a/(a+c);0=<Pod<=1\"\"\"\n",
        "def probability_of_detection(tp,tn,fp,fn):\n",
        "    pod_value = tp / (tp + fn)\n",
        "    pod_value = round(pod_value, 2)\n",
        "    #print('The POD value of model is:',pod_value)\n",
        "    return pod_value\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"#Heidke_skill_score(HSS)=Skill score based on hit rate:HSS=(Hit + Correct Negative - Chance)/(Total - Chance), where chance is the expected number of correct event forecast due to chance.\n",
        "                            #HSS=2(ad-bc)/((a+b)(b+d)+(a+c)(c+d)); (-)infinity=<HSS<=1 \"\"\"\n",
        "def heidke_skill_score(tp,tn,fp,fn):\n",
        "    heidke_skill_value = 2 * ((tp * tn) - (fn * fp)) /(((tp + fn) * (fn + tn)) + ((tp + fp) * (fp + tn)))\n",
        "    heidke_skill_value = round(heidke_skill_value,2)\n",
        "    #print('The HSS score of model is:',heidke_skill_value)\n",
        "    return heidke_skill_value\n",
        "\n",
        "\n",
        "\"\"\"#Pierce_skill_score(PSS)=Skill score based on hit rate:HSS=(Hit + Correct Negative - Chance)/(Total - Chance), where chance is the expected number of correct event forecast due to chance.\n",
        "                            #HSS=2(ad-bc)/((a+b)(b+d)+(a+c)(c+d)); (-)infinity=<HSS<=1 \"\"\"\n",
        "def pierce_skill_score(tp,tn,fp,fn):\n",
        "    pierce_skill_value = (tp / (tp + fn)) - (fp / (tp + tn))\n",
        "    pierce_skill_value = round(pierce_skill_value,2)\n",
        "    #print('The PSS score of model is:',pierce_skill_value)\n",
        "    return pierce_skill_value\n",
        "\n",
        "def f1_score(tp,tn,fp,fn):\n",
        "    f1_value = (2*(tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp)) + (tp/(tp+fn)))\n",
        "    f1_value = round(f1_value, 2)\n",
        "    #print('The F1-Score of the model is:',f1_value)\n",
        "    return f1_value"
      ],
      "metadata": {
        "id": "gYiNDhY4e8Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute class ratios\n",
        "def get_class_ratio(y, decimals=2):\n",
        "    counts = np.bincount(y)\n",
        "    total = len(y)\n",
        "    # Ensure counts has at least two elements for binary classification\n",
        "    if len(counts) < 2:\n",
        "        if 0 in y:\n",
        "            counts = np.array([counts[0], 0])\n",
        "        else:\n",
        "            counts = np.array([0, counts[0]])\n",
        "\n",
        "    ratio = {cls: round(counts[cls] / total, decimals) for cls in range(len(counts))}\n",
        "\n",
        "    # Compute imbalance ratio (majority/minority)\n",
        "    majority_count = max(counts)\n",
        "    minority_count = min(counts)\n",
        "    if minority_count > 0:\n",
        "        imbalance_ratio = f\"{round(majority_count / minority_count, decimals)} : 1\"\n",
        "    elif majority_count > 0:\n",
        "         imbalance_ratio = \"inf : 1\" # All samples are majority\n",
        "    else:\n",
        "         imbalance_ratio = \"0 : 0\" # No samples\n",
        "\n",
        "\n",
        "    return counts, ratio, imbalance_ratio"
      ],
      "metadata": {
        "id": "R-diLDvGhgBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot training history\n",
        "def plot_training_history(history, dataset_name, loss_type, save_dir):\n",
        "    \"\"\"\n",
        "    Plots training and validation metrics from the history object.\n",
        "    Saves the plots to a specified directory.\n",
        "    \"\"\"\n",
        "    # Handle cases where history might be empty or None\n",
        "    if not history:\n",
        "        print(f\"Warning: No history data available to plot for {loss_type} on {dataset_name}.\")\n",
        "        return\n",
        "\n",
        "    # Get epochs from one of the history lists (assuming all have the same length)\n",
        "    # Check if any list in history is non-empty before getting length\n",
        "    first_key = next(iter(history), None)\n",
        "    if not first_key or not history[first_key]:\n",
        "         print(f\"Warning: History dictionary is empty or its lists are empty for {loss_type} on {dataset_name}. Cannot plot.\")\n",
        "         return\n",
        "\n",
        "    epochs = range(1, len(history[first_key]) + 1)\n",
        "\n",
        "    # Define metrics to plot based on availability in history keys\n",
        "    metrics_to_plot = [key for key in history if not key.startswith('val_') and key != 'epoch']\n",
        "    val_metrics_to_plot = [key for key in history if key.startswith('val_')]\n",
        "\n",
        "\n",
        "    for metric_name in metrics_to_plot:\n",
        "        val_metric_name = f'val_{metric_name}'\n",
        "        if val_metric_name in history:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(epochs, history[metric_name], 'b', label=f'Training {metric_name.replace(\"_\", \" \")}')\n",
        "            plt.plot(epochs, history[val_metric_name], 'r', label=f'Validation {val_metric_name.replace(\"val_\", \"\").replace(\"_\", \" \")}')\n",
        "            plt.title(f'{metric_name.replace(\"_\", \" \").capitalize()} for {loss_type} on {dataset_name}')\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel(metric_name.replace(\"_\", \" \").capitalize())\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "            # Sanitize filename\n",
        "            safe_dataset_name = dataset_name.replace('.xlsx', '').replace(' ', '_').replace('-', '_')\n",
        "            safe_loss_type = loss_type.replace('-', '_')\n",
        "            filename = f\"{safe_dataset_name}_{safe_loss_type}_{metric_name}_plot.png\"\n",
        "            save_path = os.path.join(save_dir, filename)\n",
        "\n",
        "            try:\n",
        "                plt.savefig(save_path)\n",
        "                print(f\"Saved plot to: {save_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving plot {filename}: {e}\")\n",
        "\n",
        "            plt.close() # Close the figure to free up memory"
      ],
      "metadata": {
        "id": "SX9Vy6kdfZc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom train step for AMRL with gradient clipping and lambda clipping\n",
        "# Removed @tf.function decorator\n",
        "def train_step_amrl(model, loss_function, optimizer, X_batch, y_batch, clip_norm):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred_logits = model(X_batch, training=True) # Set training=True for dropout\n",
        "        loss = loss_function(y_batch, y_pred_logits)\n",
        "\n",
        "    # Get gradients for both model's trainable variables AND loss function's trainable variables\n",
        "    # Ensure all trainable variables are collected\n",
        "    trainable_variables = model.trainable_variables + loss_function.trainable_variables if hasattr(loss_function, 'trainable_variables') else model.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "    # Check for None gradients and filter\n",
        "    if any(grad is None for grad in gradients):\n",
        "        none_grads = [var.name for grad, var in zip(gradients, trainable_variables) if grad is None]\n",
        "        # print(f\"Warning: Gradients are None for variables: {none_grads}\") # Keep this for debugging if needed\n",
        "        grads_and_vars = [(grad, var) for grad, var in zip(gradients, trainable_variables) if grad is not None]\n",
        "        if not grads_and_vars:\n",
        "             # This should ideally not happen if loss and model are connected\n",
        "            raise ValueError(\"All gradients are None. Cannot apply gradients.\")\n",
        "    else:\n",
        "        grads_and_vars = list(zip(gradients, trainable_variables))\n",
        "\n",
        "\n",
        "    # Apply gradient clipping\n",
        "    clipped_gradients, _ = tf.clip_by_global_norm([g for g, v in grads_and_vars], clip_norm)\n",
        "\n",
        "    # Apply gradients\n",
        "    optimizer.apply_gradients(zip(clipped_gradients, [v for g, v in grads_and_vars]))\n",
        "\n",
        "    # Manually clip lambda values to be non-negative for AMRLLossTF after applying gradients\n",
        "    if isinstance(loss_function, AMRLLossTF):\n",
        "         if hasattr(loss_function, 'lambda1') and hasattr(loss_function, 'lambda0'):\n",
        "            loss_function.lambda1.assign(tf.maximum(0., loss_function.lambda1.numpy()))\n",
        "            loss_function.lambda0.assign(tf.maximum(0., loss_function.lambda0.numpy()))\n",
        "\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Custom test step for AMRL (used for validation)\n",
        "# Removed @tf.function decorator\n",
        "def test_step_amrl(model, loss_function, X_batch, y_batch, metrics):\n",
        "    y_pred_logits = model(X_batch, training=False) # Set training=False for dropout\n",
        "    loss = loss_function(y_batch, y_pred_logits)\n",
        "\n",
        "    # Update metrics\n",
        "    y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "    metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Custom training loop for AMRL\n",
        "def custom_train_loop(model, loss_function, optimizer, train_dataset, val_dataset, epochs, early_stopping, clip_norm):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    # Define paths for saving temporary weights\n",
        "    model_weights_path = 'temp_model_weights.weights.h5' # Corrected filename extension\n",
        "    loss_weights_path = 'temp_loss_weights.npy'\n",
        "\n",
        "\n",
        "    history = {\n",
        "        'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'auc_roc': [], 'auc_pr': [],\n",
        "        'val_loss': [], 'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_auc_roc': [], 'val_auc_pr': []\n",
        "    }\n",
        "\n",
        "    # Initialize metrics for tracking within the custom loop\n",
        "    train_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5),\n",
        "        'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5),\n",
        "        'auc_roc': AUC(),\n",
        "        'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "    val_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5),\n",
        "        'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5),\n",
        "        'auc_roc': AUC(),\n",
        "        'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # print(f\"\\nEpoch {epoch+1}/{epochs}\") # Reduced verbosity during batch processing\n",
        "\n",
        "        # Reset metrics at the start of each epoch\n",
        "        for metric in train_metrics.values():\n",
        "            metric.reset_state()\n",
        "        for metric in val_metrics.values():\n",
        "            metric.reset_state()\n",
        "\n",
        "        total_train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        for X_batch, y_batch in train_dataset:\n",
        "            loss = train_step_amrl(model, loss_function, optimizer, X_batch, y_batch, clip_norm)\n",
        "            total_train_loss += loss.numpy()\n",
        "            num_train_batches += 1\n",
        "\n",
        "            # Update train metrics (need to manually update here as train_step doesn't return probabilities/predictions)\n",
        "            # Use training=False to get deterministic predictions for metrics evaluation on the training data batch\n",
        "            y_pred_logits = model(X_batch, training=False)\n",
        "            y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "            train_metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "\n",
        "        avg_train_loss = total_train_loss / num_train_batches\n",
        "\n",
        "        total_val_loss = 0\n",
        "        num_val_batches = 0\n",
        "        for X_batch_val, y_batch_val in val_dataset:\n",
        "            loss = test_step_amrl(model, loss_function, X_batch_val, y_batch_val, val_metrics)\n",
        "            total_val_loss += loss.numpy()\n",
        "            num_val_batches += 1\n",
        "\n",
        "        avg_val_loss = total_val_loss / num_val_batches\n",
        "\n",
        "        # Get metric results\n",
        "        train_acc = train_metrics['accuracy'].result().numpy()\n",
        "        train_prec = train_metrics['precision'].result().numpy()\n",
        "        train_recall = train_metrics['recall'].result().numpy()\n",
        "        train_auc_roc = train_metrics['auc_roc'].result().numpy()\n",
        "        train_auc_pr = train_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        val_acc = val_metrics['accuracy'].result().numpy()\n",
        "        val_prec = val_metrics['precision'].result().numpy()\n",
        "        val_recall = val_metrics['recall'].result().numpy()\n",
        "        val_auc_roc = val_metrics['auc_roc'].result().numpy()\n",
        "        val_auc_pr = val_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        # Append metrics to history for plotting\n",
        "        history['loss'].append(avg_train_loss)\n",
        "        history['accuracy'].append(train_acc)\n",
        "        history['precision'].append(train_prec)\n",
        "        history['recall'].append(train_recall)\n",
        "        history['auc_roc'].append(train_auc_roc)\n",
        "        history['auc_pr'].append(train_auc_pr)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_accuracy'].append(val_acc)\n",
        "        history['val_precision'].append(val_prec)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_auc_roc'].append(val_auc_roc)\n",
        "        history['val_auc_pr'].append(val_auc_pr)\n",
        "\n",
        "\n",
        "        # Print epoch summary (reduced verbosity)\n",
        "        # print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Train Prec: {train_prec:.4f}, Train Recall: {train_recall:.4f}, Train AUC-ROC: {train_auc_roc:.4f}, Train AUC-PR: {train_auc_pr:.4f}\")\n",
        "        # print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Prec: {val_prec:.4f}, Val Recall: {val_recall:.4f}, Val AUC-ROC: {val_auc_roc:.4f}, Val AUC-PR: {val_auc_pr:.4f}\")\n",
        "\n",
        "\n",
        "        # Print the current values of the trainable loss parameters (only for AMRL)\n",
        "        if isinstance(loss_function, AMRLLossTF):\n",
        "            learned_params = [loss_function.m1.numpy(), loss_function.m0.numpy(), loss_function.lambda1.numpy(), loss_function.lambda0.numpy()]\n",
        "            # print(f\"  AMRL Learned Params: m1={learned_params[0]:.4f}, m0={learned_params[1]:.4f}, lambda1={learned_params[2]:.4f}, lambda0={learned_params[3]:.4f}\") # Reduced verbosity\n",
        "\n",
        "\n",
        "        # --- Early Stopping Check (using validation loss) ---\n",
        "        # Check if validation loss improved by at least min_delta\n",
        "        if avg_val_loss < best_val_loss - early_stopping.min_delta:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            # Save current weights if validation loss improved\n",
        "            model.save_weights(model_weights_path)\n",
        "            # Save loss function trainable variables (only for AMRL)\n",
        "            if isinstance(loss_function, AMRLLossTF):\n",
        "                 np.save(loss_weights_path, learned_params)\n",
        "            # print(\"Saved model and loss weights.\") # Reduced verbosity\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= early_stopping.patience:\n",
        "                print(f\"Early stopping triggered based on validation loss after {epoch+1} epochs.\")\n",
        "                # Restore best weights if early stopping is triggered\n",
        "                if os.path.exists(model_weights_path):\n",
        "                    print(\"Restoring model weights from best validation epoch...\")\n",
        "                    model.load_weights(model_weights_path)\n",
        "                # Restore loss parameters (only for AMRL)\n",
        "                if isinstance(loss_function, AMRLLossTF) and os.path.exists(loss_weights_path):\n",
        "                     print(\"Restoring loss parameters from best validation epoch...\")\n",
        "                     best_loss_params = np.load(loss_weights_path)\n",
        "                     loss_function.m1.assign(best_loss_params[0])\n",
        "                     loss_function.m0.assign(best_loss_params[1])\n",
        "                     loss_function.lambda1.assign(best_loss_params[2])\n",
        "                     loss_function.lambda0.assign(best_loss_params[3])\n",
        "                     # print(f\"  Restored AMRL Params: m1={loss_function.m1.numpy():.4f}, m0={loss_function.m0.numpy():.4f}, lambda1={loss_function.lambda1.numpy():.4f}, lambda0={loss_function.lambda0.numpy():.4f}\") # Reduced verbosity\n",
        "\n",
        "                break # Exit the training loop\n",
        "\n",
        "    return history # Return the history dictionary"
      ],
      "metadata": {
        "id": "uI_yCXGYfIAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyhuWqJbqUn3"
      },
      "outputs": [],
      "source": [
        "class AMRLLossTF(tf.keras.losses.Loss):\n",
        "    \"\"\"\n",
        "    Margin Loss for Imbalanced Datasets in TensorFlow.\n",
        "    Combines Weighted Binary Cross-Entropy with an Asymmetric Margin Penalty.\n",
        "    \"\"\"\n",
        "    def __init__(self, w1, w0, m1_init, m0_init, lambda1_init, lambda0_init, beta1=1, beta0=1, name=\"margin_loss_tf\"):\n",
        "        super().__init__(name=name)\n",
        "        self.w1 = tf.Variable(w1, dtype=tf.float32, trainable=False) # BCE weights are not trainable\n",
        "        self.w0 = tf.Variable(w0, dtype=tf.float32, trainable=False) # BCE weights are not trainable\n",
        "        # Make margins and lambdas trainable variables as per original design intent\n",
        "        self.m1 = tf.Variable(m1_init, dtype=tf.float32, trainable=True, name=\"m1\")\n",
        "        self.m0 = tf.Variable(m0_init, dtype=tf.float32, trainable=True, name=\"m0\")\n",
        "        self.lambda1 = tf.Variable(lambda1_init, dtype=tf.float32, trainable=True, name=\"lambda1\")\n",
        "        self.lambda0 = tf.Variable(lambda0_init, dtype=tf.float32, trainable=True, name=\"lambda0\")\n",
        "        self.beta1 = tf.constant(float(beta1), dtype=tf.float32) # Betas are constants\n",
        "        self.beta0 = tf.constant(float(beta0), dtype=tf.float32) # Betas are constants\n",
        "\n",
        "    def call(self, y_true, y_pred_logits):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred_logits = tf.cast(y_pred_logits, tf.float32)\n",
        "\n",
        "        bce_unweighted = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred_logits)\n",
        "        l_w_bce = tf.where(tf.equal(y_true, 1), bce_unweighted * self.w1, bce_unweighted * self.w0)\n",
        "\n",
        "        l_amp = tf.zeros_like(y_pred_logits)\n",
        "        penalty_minority = self.lambda1 * tf.pow(tf.maximum(0., self.m1 - y_pred_logits), self.beta1)\n",
        "        l_amp = tf.where(tf.equal(y_true, 1), penalty_minority, l_amp)\n",
        "\n",
        "        penalty_majority = self.lambda0 * tf.pow(tf.maximum(0., y_pred_logits - self.m0), self.beta0)\n",
        "        l_amp = tf.where(tf.equal(y_true, 0), penalty_majority, l_amp)\n",
        "\n",
        "        total_loss = tf.reduce_mean(l_w_bce + l_amp)\n",
        "\n",
        "        # Compare individual components:\n",
        "\n",
        "        #print(\"Weighted BCE:\", tf.reduce_mean(l_w_bce).numpy(), \"AMP:\", tf.reduce_mean(l_amp).numpy())\n",
        "\n",
        "        #print(\"Margins and Lambdas:\", self.m1.numpy(), self.m0.numpy(), self.lambda1.numpy(), self.lambda0.numpy())\n",
        "\n",
        "\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    @property\n",
        "    def trainable_variables(self):\n",
        "        # Explicitly list the trainable variables of the loss function\n",
        "        return [self.m1, self.m0, self.lambda1, self.lambda0]\n",
        "\n",
        "# --- Custom Training Step for AMRL Loss ---\n",
        "# Removed @tf.function\n",
        "def train_step_amrl(model, loss_function, optimizer, X_batch, y_batch, clip_norm):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred_logits = model(X_batch, training=True) # Set training=True for dropout\n",
        "        loss = loss_function(y_batch, y_pred_logits)\n",
        "\n",
        "    # Get gradients for both model's trainable variables AND loss function's trainable variables\n",
        "    trainable_variables = model.trainable_variables + loss_function.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "    # Apply gradient clipping\n",
        "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, clip_norm)\n",
        "\n",
        "    optimizer.apply_gradients(zip(clipped_gradients, trainable_variables))\n",
        "\n",
        "    return loss\n",
        "\n",
        "# --- Custom Test Step for AMRL Loss Evaluation ---\n",
        "# Removed @tf.function\n",
        "def test_step_amrl(model, loss_function, X_batch, y_batch, metrics):\n",
        "    y_pred_logits = model(X_batch, training=False) # Set training=False for dropout\n",
        "    loss = loss_function(y_batch, y_pred_logits)\n",
        "\n",
        "    # Update metrics\n",
        "    y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "    metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# --- Custom Training Loop for AMRL Loss ---\n",
        "def custom_train_loop(model, loss_function, optimizer, train_dataset, val_dataset, epochs, early_stopping, clip_norm):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    # Define paths for saving temporary weights\n",
        "    model_weights_path = 'temp_model_weights.weights.h5' # Corrected filename extension\n",
        "    loss_weights_path = 'temp_loss_weights.npy'\n",
        "\n",
        "    # Lists to store metric history for plotting\n",
        "    history = {\n",
        "        'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'auc_roc': [], 'auc_pr': [],\n",
        "        'val_loss': [], 'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_auc_roc': [], 'val_auc_pr': []\n",
        "    }\n",
        "\n",
        "    # Initialize metrics for tracking within the custom loop\n",
        "    train_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5),\n",
        "        'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5),\n",
        "        'auc_roc': AUC(),\n",
        "        'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "    val_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5),\n",
        "        'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5),\n",
        "        'auc_roc': AUC(),\n",
        "        'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        # Reset metrics at the start of each epoch\n",
        "        for metric in train_metrics.values():\n",
        "            metric.reset_state()\n",
        "        for metric in val_metrics.values():\n",
        "            metric.reset_state()\n",
        "\n",
        "        total_train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        for X_batch, y_batch in train_dataset:\n",
        "            loss = train_step_amrl(model, loss_function, optimizer, X_batch, y_batch, clip_norm)\n",
        "            total_train_loss += loss.numpy()\n",
        "            num_train_batches += 1\n",
        "\n",
        "            # Update train metrics (need to manually update here as train_step doesn't return probabilities/predictions)\n",
        "            y_pred_logits = model(X_batch, training=False) # Use training=False to get deterministic predictions for metrics\n",
        "            y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "            train_metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "\n",
        "        avg_train_loss = total_train_loss / num_train_batches\n",
        "\n",
        "        total_val_loss = 0\n",
        "        num_val_batches = 0\n",
        "        for X_batch_val, y_batch_val in val_dataset:\n",
        "            loss = test_step_amrl(model, loss_function, X_batch_val, y_batch_val, val_metrics)\n",
        "            total_val_loss += loss.numpy()\n",
        "            num_val_batches += 1\n",
        "\n",
        "        avg_val_loss = total_val_loss / num_val_batches\n",
        "\n",
        "        # Get metric results\n",
        "        train_acc = train_metrics['accuracy'].result().numpy()\n",
        "        train_prec = train_metrics['precision'].result().numpy()\n",
        "        train_recall = train_metrics['recall'].result().numpy()\n",
        "        train_auc_roc = train_metrics['auc_roc'].result().numpy()\n",
        "        train_auc_pr = train_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        val_acc = val_metrics['accuracy'].result().numpy()\n",
        "        val_prec = val_metrics['precision'].result().numpy()\n",
        "        val_recall = val_metrics['recall'].result().numpy()\n",
        "        val_auc_roc = val_metrics['auc_roc'].result().numpy()\n",
        "        val_auc_pr = val_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        # Append metrics to history for plotting\n",
        "        history['loss'].append(avg_train_loss)\n",
        "        history['accuracy'].append(train_acc)\n",
        "        history['precision'].append(train_prec)\n",
        "        history['recall'].append(train_recall)\n",
        "        history['auc_roc'].append(train_auc_roc)\n",
        "        history['auc_pr'].append(train_auc_pr)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_accuracy'].append(val_acc)\n",
        "        history['val_precision'].append(val_prec)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_auc_roc'].append(val_auc_roc)\n",
        "        history['val_auc_pr'].append(val_auc_pr)\n",
        "\n",
        "\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Train Prec: {train_prec:.4f}, Train Recall: {train_recall:.4f}, Train AUC-ROC: {train_auc_roc:.4f}, Train AUC-PR: {train_auc_pr:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Prec: {val_prec:.4f}, Val Recall: {val_recall:.4f}, Val AUC-ROC: {val_auc_roc:.4f}, Val AUC-PR: {val_auc_pr:.4f}\")\n",
        "\n",
        "        # Print the current values of the trainable loss parameters\n",
        "        if isinstance(loss_function, AMRLLossTF):\n",
        "            learned_params = [loss_function.m1.numpy(), loss_function.m0.numpy(), loss_function.lambda1.numpy(), loss_function.lambda0.numpy()]\n",
        "            print(f\"  AMRL Learned Params: m1={learned_params[0]:.4f}, m0={learned_params[1]:.4f}, lambda1={learned_params[2]:.4f}, lambda0={learned_params[3]:.4f}\")\n",
        "\n",
        "        # --- Custom Stopping Condition: Stop if Train Loss becomes negative ---\n",
        "        if avg_train_loss < 0:\n",
        "            print(f\"Stopping training: Train Loss became negative at epoch {epoch+1}.\")\n",
        "            # Load weights from the previous epoch (if saved)\n",
        "            if os.path.exists(model_weights_path):\n",
        "                print(\"Restoring model weights from previous epoch...\")\n",
        "                model.load_weights(model_weights_path)\n",
        "            if os.path.exists(loss_weights_path):\n",
        "                print(\"Restoring loss parameters from previous epoch...\")\n",
        "                # Assuming the order of saving is [m1, m0, lambda1, lambda0]\n",
        "                prev_loss_params = np.load(loss_weights_path)\n",
        "                loss_function.m1.assign(prev_loss_params[0])\n",
        "                loss_function.m0.assign(prev_loss_params[1])\n",
        "                loss_function.lambda1.assign(prev_loss_params[2])\n",
        "                loss_function.lambda0.assign(prev_loss_params[3])\n",
        "                print(f\"  Restored AMRL Params: m1={loss_function.m1.numpy():.4f}, m0={loss_function.m0.numpy():.4f}, lambda1={loss_function.lambda1.numpy():.4f}, lambda0={loss_function.lambda0.numpy():.4f}\")\n",
        "            break # Exit the training loop\n",
        "\n",
        "\n",
        "        # --- Early Stopping Check (using validation loss) ---\n",
        "        # Only perform early stopping based on validation loss if train loss is not negative\n",
        "        if avg_val_loss < best_val_loss - early_stopping.min_delta:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            # Save current weights if validation loss improved\n",
        "            model.save_weights(model_weights_path)\n",
        "            # Save loss function trainable variables\n",
        "            np.save(loss_weights_path, learned_params) # Save the current learned parameters\n",
        "            #print(\"Saved model and loss weights.\")\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= early_stopping.patience:\n",
        "                print(f\"Early stopping triggered based on validation loss after {epoch+1} epochs.\")\n",
        "                # Restore best weights if early stopping is triggered\n",
        "                if os.path.exists(model_weights_path):\n",
        "                    print(\"Restoring model weights from best validation epoch...\")\n",
        "                    model.load_weights(model_weights_path)\n",
        "                if os.path.exists(loss_weights_path):\n",
        "                    print(\"Restoring loss parameters from best validation epoch...\")\n",
        "                     # Assuming the order of saving is [m1, m0, lambda1, lambda0]\n",
        "                    best_loss_params = np.load(loss_weights_path)\n",
        "                    loss_function.m1.assign(best_loss_params[0])\n",
        "                    loss_function.m0.assign(best_loss_params[1])\n",
        "                    loss_function.lambda1.assign(best_loss_params[2])\n",
        "                    loss_function.lambda0.assign(best_loss_params[3])\n",
        "                    print(f\"  Restored AMRL Params: m1={loss_function.m1.numpy():.4f}, m0={loss_function.m0.numpy():.4f}, lambda1={loss_function.lambda1.numpy():.4f}, lambda0={loss_function.lambda0.numpy():.4f}\")\n",
        "\n",
        "                break # Exit the training loop\n",
        "\n",
        "    return history # Return the history dictionary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom train step for PGFL with gradient clipping\n",
        "# Removed @tf.function decorator\n",
        "def train_step_pgfl(model, loss_function, optimizer, X_batch, y_batch, clip_norm):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred_logits = model(X_batch, training=True) # Set training=True for dropout\n",
        "        loss = loss_function(y_batch, y_pred_logits) # loss.call calculates loss\n",
        "\n",
        "    # Update moving averages *after* calculating the loss and outside the gradient tape\n",
        "    # This ensures the update uses the gradients from the loss calculation\n",
        "    y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "    if isinstance(loss_function, PGFLossTF): # Only update for PGFLossTF\n",
        "        loss_function.update_confidence_moving_averages(y_batch, y_pred_probs)\n",
        "\n",
        "\n",
        "    # Get gradients for model's trainable variables AND loss function's trainable variable (alpha)\n",
        "    trainable_variables = model.trainable_variables + loss_function.trainable_variables if hasattr(loss_function, 'trainable_variables') else model.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "    # Add a check for None gradients and filter\n",
        "    if any(grad is None for grad in gradients):\n",
        "        none_grads = [var.name for grad, var in zip(gradients, trainable_variables) if grad is None]\n",
        "        # print(f\"Warning: Gradients are None for variables: {none_grads}\") # Keep this for debugging if needed\n",
        "        grads_and_vars = [(grad, var) for grad, var in zip(gradients, trainable_variables) if grad is not None]\n",
        "        if not grads_and_vars:\n",
        "            raise ValueError(\"All gradients are None. Cannot apply gradients.\")\n",
        "    else:\n",
        "        grads_and_vars = list(zip(gradients, trainable_variables))\n",
        "\n",
        "\n",
        "    # Apply gradient clipping\n",
        "    clipped_gradients, _ = tf.clip_by_global_norm([g for g, v in grads_and_vars], clip_norm)\n",
        "\n",
        "    # Apply gradients\n",
        "    optimizer.apply_gradients(zip(clipped_gradients, [v for g, v in grads_and_vars]))\n",
        "\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Custom test step for PGFL (used for validation)\n",
        "# Removed @tf.function decorator\n",
        "def test_step_pgfl(model, loss_function, X_batch, y_batch, metrics):\n",
        "    y_pred_logits = model(X_batch, training=False) # Set training=False for dropout\n",
        "    loss = loss_function(y_batch, y_pred_logits) # loss.call updates MC0/MC1 (can stay in call for test, or move out)\n",
        "\n",
        "    # Update metrics\n",
        "    y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "    metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Custom training loop for PGFL\n",
        "def custom_train_loop_pgfl(model, loss_function, optimizer, train_dataset, val_dataset, epochs, early_stopping, clip_norm):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    # Define paths for saving temporary weights for both models\n",
        "    model_weights_path = 'temp_model_weights_pgfl.weights.h5' # Separate paths for PGFL\n",
        "    loss_weights_path = 'temp_loss_weights_pgfl.npy' # Separate paths for PGFL\n",
        "\n",
        "    history = {\n",
        "        'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'auc_roc': [], 'auc_pr': [],\n",
        "        'val_loss': [], 'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_auc_roc': [], 'val_auc_pr': []\n",
        "    }\n",
        "\n",
        "    train_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5), 'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5), 'auc_roc': AUC(), 'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "    val_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5), 'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5), 'auc_roc': AUC(), 'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for metric in train_metrics.values(): metric.reset_state()\n",
        "        for metric in val_metrics.values(): metric.reset_state()\n",
        "        # Reset loss function's internal metrics (MC0, MC1) at the start of each epoch?\n",
        "        # Or let them accumulate? The description suggests moving averages over time,\n",
        "        # so perhaps don't reset per epoch, but per file. The re-initialization per file handles this.\n",
        "        # loss_function.reset_metrics() # Only if resetting per epoch is desired\n",
        "\n",
        "\n",
        "        total_train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        for i, (X_batch, y_batch) in enumerate(train_dataset): # Add enumerate to get batch index\n",
        "            loss = train_step_pgfl(model, loss_function, optimizer, X_batch, y_batch, clip_norm)\n",
        "            total_train_loss += loss.numpy()\n",
        "            num_train_batches += 1\n",
        "            # print(f\"  Batch {i}: Loss = {loss.numpy():.4f}\") # Print loss per batch\n",
        "\n",
        "\n",
        "            # Update train metrics manually\n",
        "            y_pred_logits = model(X_batch, training=False)\n",
        "            y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "            train_metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "\n",
        "        avg_train_loss = total_train_loss / num_train_batches\n",
        "\n",
        "        total_val_loss = 0\n",
        "        num_val_batches = 0\n",
        "        for X_batch_val, y_batch_val in val_dataset:\n",
        "            loss = test_step_pgfl(model, loss_function, X_batch_val, y_batch_val, val_metrics)\n",
        "            total_val_loss += loss.numpy()\n",
        "            num_val_batches += 1\n",
        "\n",
        "        avg_val_loss = total_val_loss / num_val_batches\n",
        "\n",
        "        train_acc = train_metrics['accuracy'].result().numpy()\n",
        "        train_prec = train_metrics['precision'].result().numpy()\n",
        "        train_recall = train_metrics['recall'].result().numpy()\n",
        "        train_auc_roc = train_metrics['auc_roc'].result().numpy()\n",
        "        train_auc_pr = train_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        val_acc = val_metrics['accuracy'].result().numpy()\n",
        "        val_prec = val_metrics['precision'].result().numpy()\n",
        "        val_recall = val_metrics['recall'].result().numpy()\n",
        "        val_auc_roc = val_metrics['auc_roc'].result().numpy()\n",
        "        val_auc_pr = val_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        history['loss'].append(avg_train_loss)\n",
        "        history['accuracy'].append(train_acc)\n",
        "        history['precision'].append(train_prec)\n",
        "        history['recall'].append(train_recall)\n",
        "        history['auc_roc'].append(train_auc_roc)\n",
        "        history['auc_pr'].append(train_auc_pr)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_accuracy'].append(val_acc)\n",
        "        history['val_precision'].append(val_prec)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_auc_roc'].append(val_auc_roc)\n",
        "        history['val_auc_pr'].append(val_auc_pr)\n",
        "\n",
        "\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Train Prec: {train_prec:.4f}, Train Recall: {train_recall:.4f}, Train AUC-ROC: {train_auc_roc:.4f}, Train AUC-PR: {train_auc_pr:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Prec: {val_prec:.4f}, Val Recall: {val_recall:.4f}, Val AUC-ROC: {val_auc_roc:.4f}, Val AUC-PR: {val_auc_pr:.4f}\")\n",
        "\n",
        "        # Print the current value of the trainable alpha and moving averages\n",
        "        if isinstance(loss_function, PGFLossTF):\n",
        "             print(f\"  PGFL Learned Alpha: {loss_function.alpha.numpy():.4f}, MC0: {loss_function.mc0.numpy():.4f}, MC1: {loss_function.mc1.numpy():.4f}\")\n",
        "\n",
        "\n",
        "        # --- Early Stopping Check (using validation loss) ---\n",
        "        if avg_val_loss < best_val_loss - early_stopping.min_delta:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            # Save current weights if validation loss improved\n",
        "            model.save_weights(model_weights_path)\n",
        "            # Save loss function trainable variables (alpha) and moving averages\n",
        "            np.save(loss_weights_path, [loss_function.alpha.numpy(), loss_function.mc0.numpy(), loss_function.mc1.numpy()])\n",
        "            #print(\"Saved model and PGFL loss parameters.\")\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= early_stopping.patience:\n",
        "                print(f\"Early stopping triggered based on validation loss after {epoch+1} epochs.\")\n",
        "                # Restore best weights if early stopping is triggered\n",
        "                if os.path.exists(model_weights_path):\n",
        "                    print(\"Restoring model weights from best validation epoch...\")\n",
        "                    model.load_weights(model_weights_path)\n",
        "                if os.path.exists(loss_weights_path):\n",
        "                    print(\"Restoring PGFL loss parameters from best validation epoch...\")\n",
        "                    best_loss_params = np.load(loss_weights_path)\n",
        "                    loss_function.alpha.assign(best_loss_params[0])\n",
        "                    loss_function.mc0.assign(best_loss_params[1])\n",
        "                    loss_function.mc1.assign(best_loss_params[2])\n",
        "                    print(f\"  Restored PGFL Params: Alpha={loss_function.alpha.numpy():.4f}, MC0={loss_function.mc0.numpy():.4f}, MC1={loss_function.mc1.numpy():.4f}\")\n",
        "\n",
        "                break # Exit the training loop\n",
        "\n",
        "    return history # Return the history dictionary\n"
      ],
      "metadata": {
        "id": "gw1xvOqtfXLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom train step for GAN (Generator and Discriminator)\n",
        "# Removed @tf.function decorator\n",
        "def train_step_gan(generator, discriminator, generator_optimizer, discriminator_optimizer,\n",
        "                   classification_loss_fn, X_batch, y_batch, clip_norm, gan_lambda=0.1):\n",
        "    \"\"\"\n",
        "    Performs one training step for the GAN setup.\n",
        "    Updates both the generator (classifier) and the discriminator.\n",
        "    \"\"\"\n",
        "    # --- Train Discriminator ---\n",
        "    # Train discriminator DISC_TRAIN_RATIO times for each generator step\n",
        "    for _ in range(DISC_TRAIN_RATIO):\n",
        "        with tf.GradientTape() as disc_tape:\n",
        "            # Get generator's prediction (logits or probs) for the real data batch\n",
        "            # Use training=False here for the generator during discriminator training\n",
        "            # to get deterministic output, unless dropout is specifically desired.\n",
        "            # Let's use probabilities for input to discriminator as it's a probability prediction.\n",
        "            y_pred_logits_fake = generator(X_batch, training=False)\n",
        "            y_pred_probs_fake = tf.sigmoid(y_pred_logits_fake)\n",
        "\n",
        "            # Add noise to discriminator inputs if ADD_NOISE is True\n",
        "            if ADD_NOISE:\n",
        "                 y_batch_noisy = y_batch + tf.random.normal(tf.shape(y_batch), stddev=NOISE_STDDEV)\n",
        "                 y_batch_noisy = tf.clip_by_value(y_batch_noisy, 0., 1.) # Clip to valid probability range\n",
        "\n",
        "                 y_pred_probs_fake_noisy = y_pred_probs_fake + tf.random.normal(tf.shape(y_pred_probs_fake), stddev=NOISE_STDDEV)\n",
        "                 y_pred_probs_fake_noisy = tf.clip_by_value(y_pred_probs_fake_noisy, 0., 1.)\n",
        "\n",
        "\n",
        "                 # Prepare inputs for the discriminator with noise\n",
        "                 # Real samples: [X_batch, y_batch_noisy]\n",
        "                 # Fake samples: [X_batch, y_pred_probs_fake_noisy]\n",
        "                 disc_input_real = [X_batch, y_batch_noisy]\n",
        "                 disc_input_fake = [X_batch, y_pred_probs_fake_noisy]\n",
        "\n",
        "            else:\n",
        "                 # Prepare inputs for the discriminator without noise\n",
        "                 # Real samples: [X_batch, y_batch]\n",
        "                 # Fake samples: [X_batch, y_pred_probs_fake]\n",
        "                 disc_input_real = [X_batch, y_batch]\n",
        "                 disc_input_fake = [X_batch, y_pred_probs_fake]\n",
        "\n",
        "\n",
        "            # Discriminator output for real samples (target is 1)\n",
        "            disc_output_real = discriminator(disc_input_real, training=True)\n",
        "            # Discriminator output for fake samples (target is 0)\n",
        "            disc_output_fake = discriminator(disc_input_fake, training=True)\n",
        "\n",
        "            # Calculate discriminator loss\n",
        "            # Loss for real samples (should predict 1)\n",
        "            real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(disc_output_real), disc_output_real)\n",
        "            # Loss for fake samples (should predict 0)\n",
        "            fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(disc_output_fake), disc_output_fake)\n",
        "\n",
        "            # Total discriminator loss\n",
        "            disc_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(fake_loss)\n",
        "\n",
        "        # Get and apply gradients for the discriminator\n",
        "        disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        # Apply gradient clipping to discriminator\n",
        "        clipped_disc_gradients, _ = tf.clip_by_global_norm(disc_gradients, clip_norm)\n",
        "\n",
        "        discriminator_optimizer.apply_gradients(zip(clipped_disc_gradients, discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "    # --- Train Generator ---\n",
        "    # We train the generator to make the discriminator classify fake samples as real (target is 1)\n",
        "    # Keep discriminator trainable=False during generator training\n",
        "    discriminator.trainable = False\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        # Get generator's prediction (logits) - Use training=True for dropout\n",
        "        y_pred_logits_gen = generator(X_batch, training=True)\n",
        "        y_pred_probs_gen = tf.sigmoid(y_pred_logits_gen)\n",
        "\n",
        "        # Calculate generator's classification loss (e.g., BCE or other imbalanced loss)\n",
        "        # This is the standard loss the classifier would use without the GAN component.\n",
        "        # Use from_logits=True if classification_loss_fn expects logits\n",
        "        gen_classification_loss = classification_loss_fn(y_batch, y_pred_logits_gen)\n",
        "\n",
        "        # Get discriminator's output for the generator's fake samples\n",
        "        # Now the generator wants the discriminator to think these are real (target is 1)\n",
        "        # Add noise to generator's output before feeding to discriminator if ADD_NOISE is True\n",
        "        if ADD_NOISE:\n",
        "             y_pred_probs_gen_noisy = y_pred_probs_gen + tf.random.normal(tf.shape(y_pred_probs_gen), stddev=NOISE_STDDEV)\n",
        "             y_pred_probs_gen_noisy = tf.clip_by_value(y_pred_probs_gen_noisy, 0., 1.)\n",
        "             disc_output_for_gen = discriminator([X_batch, y_pred_probs_gen_noisy], training=False) # Use training=False for discriminator here\n",
        "        else:\n",
        "             disc_output_for_gen = discriminator([X_batch, y_pred_probs_gen], training=False) # Use training=False for discriminator here\n",
        "\n",
        "\n",
        "        # Calculate generator's adversarial loss\n",
        "        # The generator wants the discriminator's output for fake samples to be close to 1.\n",
        "        gen_adversarial_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(disc_output_for_gen), disc_output_for_gen)\n",
        "\n",
        "        # Total generator loss: Combination of classification loss and adversarial loss\n",
        "        gen_total_loss = gen_classification_loss + gan_lambda * gen_adversarial_loss # gan_lambda is a weighting factor\n",
        "\n",
        "    # Get and apply gradients for the generator\n",
        "    gen_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
        "     # Apply gradient clipping to generator\n",
        "    clipped_gen_gradients, _ = tf.clip_by_global_norm(gen_gradients, clip_norm)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(clipped_gen_gradients, generator.trainable_variables))\n",
        "\n",
        "    # Set discriminator trainable back to True\n",
        "    discriminator.trainable = True\n",
        "\n",
        "    # Return losses and potentially metrics\n",
        "    return gen_total_loss, disc_loss, gen_classification_loss, gen_adversarial_loss\n",
        "\n",
        "# Custom Training Loop for GAN\n",
        "def custom_train_loop_gan(generator, discriminator, generator_optimizer, discriminator_optimizer,\n",
        "                          classification_loss_fn, train_dataset, val_dataset, epochs,\n",
        "                          early_stopping, clip_norm, gan_lambda=0.1):\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    # Define paths for saving temporary weights for both models\n",
        "    generator_weights_path = 'temp_generator_weights.weights.h5' # Separate paths for PGFL\n",
        "    discriminator_weights_path = 'temp_discriminator_weights.weights.h5' # Separate paths for PGFL\n",
        "\n",
        "\n",
        "    history = {\n",
        "        'gen_loss': [], 'disc_loss': [], 'gen_clf_loss': [], 'gen_adv_loss': [],\n",
        "        'accuracy': [], 'precision': [], 'recall': [], 'auc_roc': [], 'auc_pr': [],\n",
        "        'val_loss': [], 'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_auc_roc': [], 'val_auc_pr': []\n",
        "    }\n",
        "\n",
        "    # Initialize metrics for tracking generator performance within the custom loop\n",
        "    train_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5), 'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5), 'auc_roc': AUC(), 'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "    val_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5), 'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5), 'auc_roc': AUC(), 'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # print(f\"\\nEpoch {epoch+1}/{epochs}\") # Reduced verbosity\n",
        "\n",
        "        # Reset metrics at the start of each epoch\n",
        "        for metric in train_metrics.values(): metric.reset_state()\n",
        "        for metric in val_metrics.values(): val_metrics[metric.name].reset_state()\n",
        "\n",
        "\n",
        "        total_gen_loss = 0\n",
        "        total_disc_loss = 0\n",
        "        total_gen_clf_loss = 0\n",
        "        total_gen_adv_loss = 0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        for X_batch, y_batch in train_dataset:\n",
        "            gen_loss, disc_loss, gen_clf_loss, gen_adv_loss = train_step_gan(\n",
        "                generator, discriminator, generator_optimizer, discriminator_optimizer,\n",
        "                classification_loss_fn, X_batch, y_batch, clip_norm, gan_lambda\n",
        "            )\n",
        "            total_gen_loss += gen_loss.numpy()\n",
        "            total_disc_loss += disc_loss.numpy()\n",
        "            total_gen_clf_loss += gen_clf_loss.numpy()\n",
        "            total_gen_adv_loss += gen_adv_loss.numpy()\n",
        "            num_train_batches += 1\n",
        "\n",
        "            # Update train metrics for the generator (classifier)\n",
        "            y_pred_logits = generator(X_batch, training=False) # Use training=False for deterministic predictions\n",
        "            y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "            train_metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "\n",
        "        avg_gen_loss = total_gen_loss / num_train_batches\n",
        "        avg_disc_loss = total_disc_loss / num_train_batches\n",
        "        avg_gen_clf_loss = total_gen_clf_loss / num_train_batches\n",
        "        avg_gen_adv_loss = total_gen_adv_loss / num_train_batches\n",
        "\n",
        "\n",
        "        # Evaluate generator on validation set\n",
        "        total_val_loss = 0 # This will track the generator's classification loss on validation\n",
        "        num_val_batches = 0\n",
        "        for X_batch_val, y_batch_val in val_dataset:\n",
        "             # Calculate classification loss on validation\n",
        "            y_pred_logits_val = generator(X_batch_val, training=False)\n",
        "            val_classification_loss = classification_loss_fn(y_batch_val, y_pred_logits_val)\n",
        "            total_val_loss += val_classification_loss.numpy()\n",
        "            num_val_batches += 1\n",
        "\n",
        "            # Update val metrics for the generator\n",
        "            y_pred_probs_val = tf.sigmoid(y_pred_logits_val)\n",
        "            val_metrics['accuracy'].update_state(y_batch_val, y_pred_probs_val)\n",
        "            val_metrics['precision'].update_state(y_batch_val, y_pred_probs_val)\n",
        "            val_metrics['recall'].update_state(y_batch_val, y_pred_probs_val)\n",
        "            val_metrics['auc_roc'].update_state(y_batch_val, y_pred_probs_val)\n",
        "            val_metrics['auc_pr'].update_state(y_batch_val, y_pred_probs_val)\n",
        "\n",
        "\n",
        "        avg_val_loss = total_val_loss / num_val_batches # This is the average classification loss on validation\n",
        "\n",
        "\n",
        "        # Get metric results\n",
        "        train_acc = train_metrics['accuracy'].result().numpy()\n",
        "        train_prec = train_metrics['precision'].result().numpy()\n",
        "        train_recall = train_metrics['recall'].result().numpy()\n",
        "        train_auc_roc = train_metrics['auc_roc'].result().numpy()\n",
        "        train_auc_pr = train_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        val_acc = val_metrics['accuracy'].result().numpy()\n",
        "        val_prec = val_metrics['precision'].result().numpy()\n",
        "        val_recall = val_metrics['recall'].result().numpy()\n",
        "        val_auc_roc = val_metrics['auc_roc'].result().numpy()\n",
        "        val_auc_pr = val_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        # Append metrics to history for plotting\n",
        "        history['gen_loss'].append(avg_gen_loss)\n",
        "        history['disc_loss'].append(avg_disc_loss)\n",
        "        history['gen_clf_loss'].append(avg_gen_clf_loss)\n",
        "        history['gen_adv_loss'].append(avg_gen_adv_loss)\n",
        "        history['accuracy'].append(train_acc)\n",
        "        history['precision'].append(train_prec)\n",
        "        history['recall'].append(train_recall)\n",
        "        history['auc_roc'].append(train_auc_roc)\n",
        "        history['auc_pr'].append(train_auc_pr)\n",
        "        history['val_loss'].append(avg_val_loss) # Validation Classification Loss\n",
        "        history['val_accuracy'].append(val_acc)\n",
        "        history['val_precision'].append(val_prec)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_auc_roc'].append(val_auc_roc)\n",
        "        history['val_auc_pr'].append(val_auc_pr)\n",
        "\n",
        "\n",
        "        # print(f\"  Train Gen Loss: {avg_gen_loss:.4f}, Train Disc Loss: {avg_disc_loss:.4f}, Train Gen CLF Loss: {avg_gen_clf_loss:.4f}, Train Gen ADV Loss: {avg_gen_adv_loss:.4f}\") # Reduced verbosity\n",
        "        # print(f\"  Train Acc: {train_acc:.4f}, Train Prec: {train_prec:.4f}, Train Recall: {train_recall:.4f}, Train AUC-ROC: {train_auc_roc:.4f}, Train AUC-PR: {train_auc_pr:.4f}\") # Reduced verbosity\n",
        "        # print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Prec: {val_prec:.4f}, Val Recall: {val_recall:.4f}, Val AUC-ROC: {val_auc_roc:.4f}, Val AUC-PR: {val_auc_pr:.4f}\") # Reduced verbosity\n",
        "\n",
        "\n",
        "        # --- Early Stopping Check (using validation classification loss) ---\n",
        "        if avg_val_loss < best_val_loss - early_stopping.min_delta:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            # Save current weights if validation loss improved\n",
        "            generator.save_weights(generator_weights_path)\n",
        "            discriminator.save_weights(discriminator_weights_path)\n",
        "            #print(\"Saved generator and discriminator weights.\")\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= early_stopping.patience:\n",
        "                print(f\"Early stopping triggered based on validation loss after {epoch+1} epochs.\")\n",
        "                # Restore best weights if early stopping is triggered\n",
        "                if os.path.exists(generator_weights_path):\n",
        "                    print(\"Restoring generator weights from best validation epoch...\")\n",
        "                    generator.load_weights(generator_weights_path)\n",
        "                if os.path.exists(discriminator_weights_path):\n",
        "                    print(\"Restoring discriminator weights from best validation epoch...\")\n",
        "                    discriminator.load_weights(discriminator_weights_path)\n",
        "\n",
        "                break # Exit the training loop\n",
        "\n",
        "    return history # Return the history dictionary"
      ],
      "metadata": {
        "id": "FOvjKfw6hYso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nCVw58y0Pg3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model, layers # Import Model and layers\n",
        "\n",
        "class Discriminator(Model):\n",
        "    \"\"\"\n",
        "    Discriminator network for GAN-based imbalanced classification.\n",
        "    Takes features (X) and classifier output (logits or probabilities) as input\n",
        "    and outputs the probability that the sample is 'real' (from the true distribution).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim_X, input_dim_Y):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # The discriminator needs to handle both the features X and the classifier's output Y.\n",
        "        # We can concatenate them or process them separately and combine later.\n",
        "        # A simple approach is concatenation after potential initial processing.\n",
        "        # Let's start with concatenating the raw features and the classifier's single output (logit or probability).\n",
        "        # Total input dimension will be input_dim_X + input_dim_Y (which is 1 for binary classification output).\n",
        "        combined_input_dim = input_dim_X + input_dim_Y\n",
        "\n",
        "        self.fc1 = layers.Dense(64, activation='relu', input_shape=(combined_input_dim,))\n",
        "        self.dropout1 = layers.Dropout(0.3)\n",
        "        self.fc2 = layers.Dense(32, activation='relu')\n",
        "        self.dropout2 = layers.Dropout(0.3)\n",
        "        # Output layer: single unit with sigmoid activation for real/fake probability\n",
        "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        # inputs is expected to be a tuple or list: [X, Y_classifier_output]\n",
        "        X_input, Y_classifier_output = inputs\n",
        "\n",
        "        # Ensure Y_classifier_output has a shape that can be concatenated (e.g., reshape if needed)\n",
        "        # For binary classification logits/probs, it should be (batch_size, 1)\n",
        "        if tf.rank(Y_classifier_output) == 0:\n",
        "             Y_classifier_output = tf.reshape(Y_classifier_output, (-1, 1))\n",
        "        elif tf.rank(Y_classifier_output) == 1:\n",
        "             Y_classifier_output = tf.expand_dims(Y_classifier_output, axis=-1)\n",
        "\n",
        "\n",
        "        # Concatenate features and classifier output\n",
        "        combined_input = tf.concat([X_input, Y_classifier_output], axis=-1)\n",
        "\n",
        "        x = self.fc1(combined_input)\n",
        "        x = self.dropout1(x, training=training)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "        discriminator_output = self.output_layer(x)\n",
        "\n",
        "        return discriminator_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1e8744f"
      },
      "outputs": [],
      "source": [
        "# --- Custom Training Step for GAN (Generator and Discriminator) ---\n",
        "# This function will perform one training iteration, including updating both\n",
        "# the generator (SimpleMLP_TF) and the discriminator.\n",
        "\n",
        "# We need separate optimizers for the generator and discriminator.\n",
        "# Let's define them outside this function.\n",
        "\n",
        "# We also need a base classification loss (e.g., BCE) for the generator.\n",
        "# Let's define that outside as well.\n",
        "\n",
        "def train_step_gan(generator, discriminator, generator_optimizer, discriminator_optimizer,\n",
        "                   classification_loss_fn, X_batch, y_batch, clip_norm, gan_lambda=0.1):\n",
        "    \"\"\"\n",
        "    Performs one training step for the GAN setup.\n",
        "    Updates both the generator (classifier) and the discriminator.\n",
        "    \"\"\"\n",
        "    # --- Train Discriminator ---\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "        # Get generator's prediction (logits or probs) for the real data batch\n",
        "        # Use training=False here for the generator during discriminator training\n",
        "        # to get deterministic output, unless dropout is specifically desired.\n",
        "        # Let's use logits for consistency with classification loss.\n",
        "        y_pred_logits_fake = generator(X_batch, training=False)\n",
        "        y_pred_probs_fake = tf.sigmoid(y_pred_logits_fake)\n",
        "\n",
        "        # Prepare inputs for the discriminator\n",
        "        # Real samples: [X_batch, y_batch]\n",
        "        # Fake samples: [X_batch, y_pred_probs_fake] (using probabilities for fake)\n",
        "\n",
        "        # Discriminator output for real samples (target is 1)\n",
        "        disc_output_real = discriminator([X_batch, y_batch], training=True)\n",
        "        # Discriminator output for fake samples (target is 0)\n",
        "        disc_output_fake = discriminator([X_batch, y_pred_probs_fake], training=True)\n",
        "\n",
        "        # Calculate discriminator loss\n",
        "        # Loss for real samples (should predict 1)\n",
        "        real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(disc_output_real), disc_output_real)\n",
        "        # Loss for fake samples (should predict 0)\n",
        "        fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(disc_output_fake), disc_output_fake)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        disc_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(fake_loss)\n",
        "\n",
        "    # Get and apply gradients for the discriminator\n",
        "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    # Apply gradient clipping to discriminator\n",
        "    clipped_disc_gradients, _ = tf.clip_by_global_norm(disc_gradients, clip_norm)\n",
        "\n",
        "    discriminator_optimizer.apply_gradients(zip(clipped_disc_gradients, discriminator.trainable_variables))\n",
        "\n",
        "    # --- Train Generator ---\n",
        "    # We train the generator to make the discriminator classify fake samples as real (target is 1)\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        # Get generator's prediction (logits) - Use training=True for dropout\n",
        "        y_pred_logits_gen = generator(X_batch, training=True)\n",
        "        y_pred_probs_gen = tf.sigmoid(y_pred_logits_gen)\n",
        "\n",
        "        # Calculate generator's classification loss (e.g., BCE or other imbalanced loss)\n",
        "        # This is the standard loss the classifier would use without the GAN component.\n",
        "        # Use from_logits=True if classification_loss_fn expects logits\n",
        "        gen_classification_loss = classification_loss_fn(y_batch, y_pred_logits_gen)\n",
        "\n",
        "        # Get discriminator's output for the generator's fake samples\n",
        "        # Now the generator wants the discriminator to think these are real (target is 1)\n",
        "        disc_output_for_gen = discriminator([X_batch, y_pred_probs_gen], training=False) # Use training=False for discriminator here\n",
        "\n",
        "        # Calculate generator's adversarial loss\n",
        "        # The generator wants the discriminator's output for fake samples to be close to 1.\n",
        "        gen_adversarial_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(disc_output_for_gen), disc_output_for_gen)\n",
        "\n",
        "        # Total generator loss: Combination of classification loss and adversarial loss\n",
        "        gen_total_loss = gen_classification_loss + gan_lambda * gen_adversarial_loss # gan_lambda is a weighting factor\n",
        "\n",
        "    # Get and apply gradients for the generator\n",
        "    gen_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
        "     # Apply gradient clipping to generator\n",
        "    clipped_gen_gradients, _ = tf.clip_by_global_norm(gen_gradients, clip_norm)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(clipped_gen_gradients, generator.trainable_variables))\n",
        "\n",
        "    # Return losses and potentially metrics\n",
        "    # Ensure losses are returned as scalar numpy values for easier accumulation\n",
        "    return gen_total_loss.numpy(), disc_loss.numpy(), gen_classification_loss.numpy(), gen_adversarial_loss.numpy()\n",
        "\n",
        "# --- Custom Training Loop for GAN ---\n",
        "# This loop will orchestrate the training steps, including early stopping.\n",
        "# It needs to track metrics for both generator and discriminator if desired,\n",
        "# but the primary focus is on the generator's performance on the classification task.\n",
        "\n",
        "def custom_train_loop_gan(generator, discriminator, generator_optimizer, discriminator_optimizer,\n",
        "                          classification_loss_fn, train_dataset, val_dataset, epochs,\n",
        "                          early_stopping, clip_norm, gan_lambda=0.1):\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    # Define paths for saving temporary weights for both models\n",
        "    generator_weights_path = 'temp_generator_weights.weights.h5'\n",
        "    discriminator_weights_path = 'temp_discriminator_weights.weights.h5'\n",
        "\n",
        "\n",
        "    history = {\n",
        "        'gen_loss': [], 'disc_loss': [], 'gen_clf_loss': [], 'gen_adv_loss': [],\n",
        "        'accuracy': [], 'precision': [], 'recall': [], 'auc_roc': [], 'auc_pr': [],\n",
        "        'val_loss': [], 'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_auc_roc': [], 'val_auc_pr': []\n",
        "    }\n",
        "\n",
        "    # Initialize metrics for tracking generator performance within the custom loop\n",
        "    train_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5), 'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5), 'auc_roc': AUC(), 'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "    val_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5), 'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5), 'auc_roc': AUC(), 'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        # Reset metrics at the start of each epoch\n",
        "        for metric in train_metrics.values(): metric.reset_state()\n",
        "        for metric in val_metrics.values(): val_metrics[metric.name].reset_state()\n",
        "\n",
        "\n",
        "        total_gen_loss = 0\n",
        "        total_disc_loss = 0\n",
        "        total_gen_clf_loss = 0\n",
        "        total_gen_adv_loss = 0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        for X_batch, y_batch in train_dataset:\n",
        "            gen_loss, disc_loss, gen_clf_loss, gen_adv_loss = train_step_gan(\n",
        "                generator, discriminator, generator_optimizer, discriminator_optimizer,\n",
        "                classification_loss_fn, X_batch, y_batch, clip_norm, gan_lambda\n",
        "            )\n",
        "            total_gen_loss += gen_loss\n",
        "            total_disc_loss += disc_loss\n",
        "            total_gen_clf_loss += gen_clf_loss\n",
        "            total_gen_adv_loss += gen_adv_loss\n",
        "            num_train_batches += 1\n",
        "\n",
        "            # Update train metrics for the generator (classifier)\n",
        "            y_pred_logits = generator(X_batch, training=False) # Use training=False for deterministic predictions\n",
        "            y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "            train_metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "\n",
        "        avg_gen_loss = total_gen_loss / num_train_batches\n",
        "        avg_disc_loss = total_disc_loss / num_train_batches\n",
        "        avg_gen_clf_loss = total_gen_clf_loss / num_train_batches\n",
        "        avg_gen_adv_loss = total_gen_adv_loss / num_train_batches\n",
        "\n",
        "\n",
        "        # Evaluate generator on validation set\n",
        "        total_val_loss = 0 # This will track the generator's classification loss on validation\n",
        "        num_val_batches = 0\n",
        "        for X_batch_val, y_batch_val in val_dataset:\n",
        "             # Calculate classification loss on validation\n",
        "            y_pred_logits_val = generator(X_batch_val, training=False)\n",
        "            val_classification_loss = classification_loss_fn(y_batch_val, y_pred_logits_val)\n",
        "            total_val_loss += val_classification_loss.numpy()\n",
        "            num_val_batches += 1\n",
        "\n",
        "            # Update val metrics for the generator\n",
        "            y_pred_probs_val = tf.sigmoid(y_pred_logits_val)\n",
        "            val_metrics['accuracy'].update_state(y_batch_val, y_pred_probs_val)\n",
        "            val_metrics['precision'].update_state(y_batch_val, y_pred_probs_val)\n",
        "            val_metrics['recall'].update_state(y_batch_val, y_pred_probs_val)\n",
        "            val_metrics['auc_roc'].update_state(y_batch_val, y_pred_probs_val)\n",
        "            val_metrics['auc_pr'].update_state(y_batch_val, y_pred_probs_val)\n",
        "\n",
        "\n",
        "        avg_val_loss = total_val_loss / num_val_batches # This is the average classification loss on validation\n",
        "\n",
        "\n",
        "        # Get metric results\n",
        "        train_acc = train_metrics['accuracy'].result().numpy()\n",
        "        train_prec = train_metrics['precision'].result().numpy()\n",
        "        train_recall = train_metrics['recall'].result().numpy()\n",
        "        train_auc_roc = train_metrics['auc_roc'].result().numpy()\n",
        "        train_auc_pr = train_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        val_acc = val_metrics['accuracy'].result().numpy()\n",
        "        val_prec = val_metrics['precision'].result().numpy()\n",
        "        val_recall = val_metrics['recall'].result().numpy()\n",
        "        val_auc_roc = val_metrics['auc_roc'].result().numpy()\n",
        "        val_auc_pr = val_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        # Append metrics to history for plotting\n",
        "        history['gen_loss'].append(avg_gen_loss)\n",
        "        history['disc_loss'].append(avg_disc_loss)\n",
        "        history['gen_clf_loss'].append(avg_gen_clf_loss)\n",
        "        history['gen_adv_loss'].append(avg_gen_adv_loss)\n",
        "        history['accuracy'].append(train_acc)\n",
        "        history['precision'].append(train_prec)\n",
        "        history['recall'].append(train_recall)\n",
        "        history['auc_roc'].append(train_auc_roc)\n",
        "        history['auc_pr'].append(train_auc_pr)\n",
        "        history['val_loss'].append(avg_val_loss) # Validation Classification Loss\n",
        "        history['val_accuracy'].append(val_acc)\n",
        "        history['val_precision'].append(val_prec)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_auc_roc'].append(val_auc_roc)\n",
        "        history['val_auc_pr'].append(val_auc_pr)\n",
        "\n",
        "\n",
        "        # print(f\"Train Gen Loss: {avg_gen_loss:.4f}, Train Disc Loss: {avg_disc_loss:.4f}, Train Gen CLF Loss: {avg_gen_clf_loss:.4f}, Train Gen ADV Loss: {avg_gen_adv_loss:.4f}\")\n",
        "        # print(f\"Train Acc: {train_acc:.4f}, Train Prec: {train_prec:.4f}, Train Recall: {train_recall:.4f}, Train AUC-ROC: {train_auc_roc:.4f}, Train AUC-PR: {train_auc_pr:.4f}\")\n",
        "        # print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Prec: {val_prec:.4f}, Val Recall: {val_recall:.4f}, Val AUC-ROC: {val_auc_roc:.4f}, Val AUC-PR: {val_auc_pr:.4f}\")\n",
        "\n",
        "\n",
        "        # --- Early Stopping Check (using validation classification loss) ---\n",
        "        if avg_val_loss < best_val_loss - early_stopping.min_delta:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            # Save current weights if validation loss improved\n",
        "            generator.save_weights(generator_weights_path)\n",
        "            discriminator.save_weights(discriminator_weights_path)\n",
        "            #print(\"Saved generator and discriminator weights.\")\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= early_stopping.patience:\n",
        "                print(f\"Early stopping triggered based on validation loss after {epoch+1} epochs.\")\n",
        "                # Restore best weights if early stopping is triggered\n",
        "                if os.path.exists(generator_weights_path):\n",
        "                    print(\"Restoring generator weights from best validation epoch...\")\n",
        "                    generator.load_weights(generator_weights_path)\n",
        "                if os.path.exists(discriminator_weights_path):\n",
        "                    print(\"Restoring discriminator weights from best validation epoch...\")\n",
        "                    discriminator.load_weights(discriminator_weights_path)\n",
        "\n",
        "                break # Exit the training loop\n",
        "\n",
        "    return history # Return the history dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eb90146"
      },
      "outputs": [],
      "source": [
        "class PGFLossTF(tf.keras.losses.Loss):\n",
        "    \"\"\"\n",
        "    Proposed Geometric Focal Loss (PGFL) for Imbalanced Datasets in TensorFlow.\n",
        "    Combines dynamic class weighting based on confidence with Focal Loss.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_majority, num_minority, gamma=2.0, alpha_init=None, name=\"pgf_loss_tf\"):\n",
        "        super().__init__(name=name)\n",
        "        self.gamma = tf.constant(gamma, dtype=tf.float32)\n",
        "\n",
        "        # Initialize alpha (adaptive weight for minority class)\n",
        "        # If alpha_init is not provided, use initial inverse frequency\n",
        "        if alpha_init is None:\n",
        "            initial_alpha = tf.cast(num_majority / (num_majority + num_minority), dtype=tf.float32)\n",
        "        else:\n",
        "            initial_alpha = tf.constant(alpha_init, dtype=tf.float32)\n",
        "\n",
        "        # Make alpha a trainable variable for dynamic adaptation\n",
        "        self.alpha = tf.Variable(initial_alpha, dtype=tf.float32, trainable=True, name=\"alpha\")\n",
        "\n",
        "        # Moving averages for confidence (non-trainable)\n",
        "        self.mc0 = tf.Variable(0.0, dtype=tf.float32, trainable=False, name=\"mc0\") # Confidence for correctly classified majority\n",
        "        self.mc1 = tf.Variable(0.0, dtype=tf.float32, trainable=False, name=\"mc1\") # Confidence for correctly classified minority\n",
        "        self.momentum = tf.constant(0.99, dtype=tf.float32) # Momentum for moving averages\n",
        "\n",
        "        # Track counts for updating moving averages (non-trainable)\n",
        "        self.count0 = tf.Variable(0.0, dtype=tf.float32, trainable=False, name=\"count0\")\n",
        "        self.count1 = tf.Variable(0.0, dtype=tf.float32, trainable=False, name=\"count1\")\n",
        "\n",
        "\n",
        "    def update_confidence_moving_averages(self, y_true, y_pred_probs):\n",
        "        \"\"\"Updates the moving averages of confidence for correctly classified samples.\"\"\"\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred_probs = tf.cast(y_pred_probs, tf.float32)\n",
        "\n",
        "        # Identify correctly classified samples\n",
        "        predicted_labels = tf.cast(y_pred_probs > 0.5, tf.float32)\n",
        "        correctly_classified_mask = tf.equal(predicted_labels, y_true)\n",
        "\n",
        "        # Separate based on true class\n",
        "        majority_mask = tf.equal(y_true, 0)\n",
        "        minority_mask = tf.equal(y_true, 1)\n",
        "\n",
        "        # Correctly classified majority samples\n",
        "        cc_majority_mask = tf.logical_and(correctly_classified_mask, majority_mask)\n",
        "        cc_majority_probs = tf.boolean_mask(1.0 - y_pred_probs, cc_majority_mask) # Confidence for majority is 1 - prob of minority\n",
        "        num_cc_majority = tf.cast(tf.shape(cc_majority_probs)[0], tf.float32)\n",
        "\n",
        "        # Correctly classified minority samples\n",
        "        cc_minority_mask = tf.logical_and(correctly_classified_mask, minority_mask)\n",
        "        cc_minority_probs = tf.boolean_mask(y_pred_probs, cc_minority_mask) # Confidence for minority is prob of minority\n",
        "        num_cc_minority = tf.cast(tf.shape(cc_minority_probs)[0], tf.float32)\n",
        "\n",
        "\n",
        "        # Update moving averages if there are correctly classified samples\n",
        "        if num_cc_majority > 0:\n",
        "            avg_cc_majority_confidence = tf.reduce_mean(cc_majority_probs)\n",
        "            self.mc0.assign(self.momentum * self.mc0 + (1.0 - self.momentum) * avg_cc_majority_confidence)\n",
        "            self.count0.assign(self.count0 + num_cc_majority)\n",
        "\n",
        "        if num_cc_minority > 0:\n",
        "            avg_cc_minority_confidence = tf.reduce_mean(cc_minority_probs)\n",
        "            self.mc1.assign(self.momentum * self.mc1 + (1.0 - self.momentum) * avg_cc_minority_confidence)\n",
        "            self.count1.assign(self.count1 + num_cc_minority)\n",
        "\n",
        "\n",
        "    def update_alpha_dynamically(self):\n",
        "        \"\"\"Dynamically updates alpha based on the moving averages of confidence.\"\"\"\n",
        "        # Avoid division by zero if no samples of a class have been correctly classified yet\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "\n",
        "        # Simple dynamic update: increase alpha if confidence in minority is lower than majority\n",
        "        # Or, increase alpha if minority class is misclassified more often (indirectly via lower MC1)\n",
        "        # This is a conceptual implementation, can be refined.\n",
        "        # For example, alpha could be a sigmoid of a difference or ratio of confidences.\n",
        "\n",
        "        # Let's try a simple ratio-based update for demonstration:\n",
        "        # If MC1 is much lower than MC0, increase alpha towards 1.\n",
        "        # If MC0 is much lower than MC1, decrease alpha towards 0.\n",
        "        # Add epsilon to avoid division by zero\n",
        "        confidence_ratio = (self.mc1 + epsilon) / (self.mc0 + epsilon)\n",
        "\n",
        "        # Map the ratio to an alpha update. This mapping can be tuned.\n",
        "        # A simple approach: if ratio < 1, increase alpha; if ratio > 1, decrease alpha.\n",
        "        # The magnitude of change could depend on how far the ratio is from 1.\n",
        "        # Example: alpha = sigmoid(k * (MC0 - MC1)) for some scaling factor k\n",
        "        # Or, alpha = initial_alpha * (1 + delta * (MC0 - MC1))\n",
        "\n",
        "        # Let's use a sigmoid based on the difference for a smoother update:\n",
        "        # Scale the difference to make it more impactful if needed\n",
        "        scaled_confidence_difference = 1.0 * (self.mc0 - self.mc1) # Adjust scaling factor as needed\n",
        "\n",
        "        # Use sigmoid to map the difference to a value between 0 and 1\n",
        "        # If MC0 > MC1 (majority easier/more confident), sigmoid(positive) > 0.5 -> increase alpha\n",
        "        # If MC1 > MC0 (minority easier/more confident), sigmoid(negative) < 0.5 -> decrease alpha\n",
        "        # This direction seems counter-intuitive based on the description \"increase the weight of the class that the model is less confident about\".\n",
        "        # Let's adjust: increase alpha if MC1 (minority confidence) is low relative to MC0 (majority confidence).\n",
        "        # So, we want alpha to increase as (MC0 - MC1) increases. Sigmoid(MC0 - MC1) works for this.\n",
        "\n",
        "        # Let's try a simpler update rule first: adjust alpha based on the sign of the confidence difference.\n",
        "        # If minority confidence is lower than majority confidence (MC1 < MC0), slightly increase alpha.\n",
        "        # If majority confidence is lower than minority confidence (MC0 < MC1), slightly decrease alpha.\n",
        "        # This requires a learning rate for alpha itself.\n",
        "\n",
        "        # A better approach might be to directly train alpha as a variable, as initially intended.\n",
        "        # The moving averages MC0 and MC1 can then be used *within* the loss function's calculation\n",
        "        # to modulate the per-sample loss based on confidence, rather than directly updating alpha.\n",
        "\n",
        "        # Let's stick to the original plan of training alpha and use MC0/MC1 for monitoring or\n",
        "        # potentially in a more complex update rule if needed later.\n",
        "        # For now, the trainable self.alpha is the 'adaptive' part. The moving averages MC0 and MC1\n",
        "        # can serve as indicators of which class the model is struggling with, which might guide\n",
        "        # hyperparameter tuning of the initial alpha or the learning rate for alpha.\n",
        "\n",
        "        # Let's keep self.alpha trainable and remove the direct update based on MC0/MC1 for now.\n",
        "        # The 'adaptiveness' comes from the optimizer adjusting self.alpha during training.\n",
        "        pass # No direct update to self.alpha here\n",
        "\n",
        "    def call(self, y_true, y_pred_logits):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred_logits = tf.cast(y_pred_logits, tf.float32)\n",
        "\n",
        "        # Calculate probabilities\n",
        "        p = tf.sigmoid(y_pred_logits)\n",
        "\n",
        "        # Update moving averages of confidence with the current batch's predictions\n",
        "        # This should ideally be done after the optimizer step, but for simplicity in a single call method,\n",
        "        # we'll update it here. This makes the update slightly delayed.\n",
        "        # A more accurate approach might involve a custom training loop that updates MC0/MC1 after gradients are applied.\n",
        "        # For now, let's update it here for demonstration.\n",
        "        self.update_confidence_moving_averages(y_true, p)\n",
        "\n",
        "\n",
        "        # Calculate standard BCE\n",
        "        bce_unweighted = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred_logits)\n",
        "\n",
        "        # p_t is the probability of the true class\n",
        "        p_t = y_true * p + (1 - y_true) * (1 - p)\n",
        "\n",
        "        # Modulating factor (1 - p_t)^gamma\n",
        "        modulating_factor = tf.pow(1.0 - p_t, self.gamma)\n",
        "\n",
        "        # Adaptive alpha_t: Use the trainable self.alpha\n",
        "        # alpha_t is alpha for positive (minority), 1-alpha for negative (majority)\n",
        "        alpha_t = y_true * self.alpha + (1 - y_true) * (1.0 - self.alpha)\n",
        "\n",
        "        # PGFL Loss: alpha_t * (1 - p_t)^gamma * BCE\n",
        "        pgf_loss = alpha_t * modulating_factor * bce_unweighted\n",
        "\n",
        "        # Add print statements for debugging\n",
        "        # tf.print(\"y_true:\", y_true, summarize=-1)\n",
        "        # tf.print(\"y_pred_logits:\", y_pred_logits, summarize=-1)\n",
        "        # tf.print(\"p:\", p, summarize=-1)\n",
        "        # tf.print(\"bce_unweighted:\", bce_unweighted, summarize=-1)\n",
        "        # tf.print(\"p_t:\", p_t, summarize=-1)\n",
        "        # tf.print(\"modulating_factor:\", modulating_factor, summarize=-1)\n",
        "        # tf.print(\"alpha_t:\", alpha_t, summarize=-1)\n",
        "        # tf.print(\"pgf_loss (per sample):\", pgf_loss, summarize=-1)\n",
        "        # tf.print(\"pgf_loss (mean):\", tf.reduce_mean(pgf_loss), summarize=-1)\n",
        "\n",
        "        return tf.reduce_mean(pgf_loss)\n",
        "\n",
        "    @property\n",
        "    def trainable_variables(self):\n",
        "        # The only trainable variable in this loss is alpha\n",
        "        return [self.alpha]\n",
        "\n",
        "    def reset_metrics(self):\n",
        "        \"\"\"Resets the state of the moving average variables.\"\"\"\n",
        "        self.mc0.assign(0.0)\n",
        "        self.mc1.assign(0.0)\n",
        "        self.count0.assign(0.0)\n",
        "        self.count1.assign(0.0)\n",
        "        # Note: self.alpha is trainable and should not be reset between epochs/files\n",
        "        # unless specifically desired. For comparison across files, the model and loss\n",
        "        # are re-initialized, which handles this."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Custom train step for PGFL with gradient clipping\n",
        "# Removed @tf.function decorator\n",
        "def train_step_pgfl(model, loss_function, optimizer, X_batch, y_batch, clip_norm):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred_logits = model(X_batch, training=True) # Set training=True for dropout\n",
        "        loss = loss_function(y_batch, y_pred_logits) # loss.call calculates loss\n",
        "\n",
        "    # Update moving averages *after* calculating the loss and outside the gradient tape\n",
        "    # This ensures the update uses the gradients from the loss calculation\n",
        "    y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "    if isinstance(loss_function, PGFLossTF): # Only update for PGFLossTF\n",
        "        loss_function.update_confidence_moving_averages(y_batch, y_pred_probs)\n",
        "\n",
        "\n",
        "    # Get gradients for model's trainable variables AND loss function's trainable variable (alpha)\n",
        "    trainable_variables = model.trainable_variables + loss_function.trainable_variables if hasattr(loss_function, 'trainable_variables') else model.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "    # Add a check for None gradients and filter\n",
        "    if any(grad is None for grad in gradients):\n",
        "        none_grads = [var.name for grad, var in zip(gradients, trainable_variables) if grad is None]\n",
        "        # print(f\"Warning: Gradients are None for variables: {none_grads}\") # Keep this for debugging if needed\n",
        "        grads_and_vars = [(grad, var) for grad, var in zip(gradients, trainable_variables) if grad is not None]\n",
        "        if not grads_and_vars:\n",
        "            raise ValueError(\"All gradients are None. Cannot apply gradients.\")\n",
        "    else:\n",
        "        grads_and_vars = list(zip(gradients, trainable_variables))\n",
        "\n",
        "\n",
        "    # Apply gradient clipping\n",
        "    clipped_gradients, _ = tf.clip_by_global_norm([g for g, v in grads_and_vars], clip_norm)\n",
        "\n",
        "    # Apply gradients\n",
        "    optimizer.apply_gradients(zip(clipped_gradients, [v for g, v in grads_and_vars]))\n",
        "\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Custom test step for PGFL (used for validation)\n",
        "# Removed @tf.function decorator\n",
        "def test_step_pgfl(model, loss_function, X_batch, y_batch, metrics):\n",
        "    y_pred_logits = model(X_batch, training=False) # Set training=False for dropout\n",
        "    loss = loss_function(y_batch, y_pred_logits) # loss.call updates MC0/MC1 (can stay in call for test, or move out)\n",
        "\n",
        "    # Update metrics\n",
        "    y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "    metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "    metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Custom training loop for PGFL\n",
        "def custom_train_loop_pgfl(model, loss_function, optimizer, train_dataset, val_dataset, epochs, early_stopping, clip_norm):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    # Define paths for saving temporary weights for both models\n",
        "    model_weights_path = 'temp_model_weights_pgfl.weights.h5' # Separate paths for PGFL\n",
        "    loss_weights_path = 'temp_loss_weights_pgfl.npy' # Separate paths for PGFL\n",
        "\n",
        "    history = {\n",
        "        'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'auc_roc': [], 'auc_pr': [],\n",
        "        'val_loss': [], 'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_auc_roc': [], 'val_auc_pr': []\n",
        "    }\n",
        "\n",
        "    train_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5), 'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5), 'auc_roc': AUC(), 'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "    val_metrics = {\n",
        "        'accuracy': BinaryAccuracy(threshold=0.5), 'precision': Precision(thresholds=0.5),\n",
        "        'recall': Recall(thresholds=0.5), 'auc_roc': AUC(), 'auc_pr': AUC(curve='PR')\n",
        "    }\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for metric in train_metrics.values(): metric.reset_state()\n",
        "        for metric in val_metrics.values(): metric.reset_state()\n",
        "        # Reset loss function's internal metrics (MC0, MC1) at the start of each epoch?\n",
        "        # Or let them accumulate? The description suggests moving averages over time,\n",
        "        # so perhaps don't reset per epoch, but per file. The re-initialization per file handles this.\n",
        "        # loss_function.reset_metrics() # Only if resetting per epoch is desired\n",
        "\n",
        "\n",
        "        total_train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        for i, (X_batch, y_batch) in enumerate(train_dataset): # Add enumerate to get batch index\n",
        "            loss = train_step_pgfl(model, loss_function, optimizer, X_batch, y_batch, clip_norm)\n",
        "            total_train_loss += loss.numpy()\n",
        "            num_train_batches += 1\n",
        "            # print(f\"  Batch {i}: Loss = {loss.numpy():.4f}\") # Print loss per batch\n",
        "\n",
        "\n",
        "            # Update train metrics manually\n",
        "            y_pred_logits = model(X_batch, training=False)\n",
        "            y_pred_probs = tf.sigmoid(y_pred_logits)\n",
        "            train_metrics['accuracy'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['precision'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['recall'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_roc'].update_state(y_batch, y_pred_probs)\n",
        "            train_metrics['auc_pr'].update_state(y_batch, y_pred_probs)\n",
        "\n",
        "\n",
        "        avg_train_loss = total_train_loss / num_train_batches\n",
        "\n",
        "        total_val_loss = 0\n",
        "        num_val_batches = 0\n",
        "        for X_batch_val, y_batch_val in val_dataset:\n",
        "            loss = test_step_pgfl(model, loss_function, X_batch_val, y_batch_val, val_metrics)\n",
        "            total_val_loss += loss.numpy()\n",
        "            num_val_batches += 1\n",
        "\n",
        "        avg_val_loss = total_val_loss / num_val_batches\n",
        "\n",
        "        train_acc = train_metrics['accuracy'].result().numpy()\n",
        "        train_prec = train_metrics['precision'].result().numpy()\n",
        "        train_recall = train_metrics['recall'].result().numpy()\n",
        "        train_auc_roc = train_metrics['auc_roc'].result().numpy()\n",
        "        train_auc_pr = train_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        val_acc = val_metrics['accuracy'].result().numpy()\n",
        "        val_prec = val_metrics['precision'].result().numpy()\n",
        "        val_recall = val_metrics['recall'].result().numpy()\n",
        "        val_auc_roc = val_metrics['auc_roc'].result().numpy()\n",
        "        val_auc_pr = val_metrics['auc_pr'].result().numpy()\n",
        "\n",
        "        history['loss'].append(avg_train_loss)\n",
        "        history['accuracy'].append(train_acc)\n",
        "        history['precision'].append(train_prec)\n",
        "        history['recall'].append(train_recall)\n",
        "        history['auc_roc'].append(train_auc_roc)\n",
        "        history['auc_pr'].append(train_auc_pr)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_accuracy'].append(val_acc)\n",
        "        history['val_precision'].append(val_prec)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_auc_roc'].append(val_auc_roc)\n",
        "        history['val_auc_pr'].append(val_auc_pr)\n",
        "\n",
        "\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Train Prec: {train_prec:.4f}, Train Recall: {train_recall:.4f}, Train AUC-ROC: {train_auc_roc:.4f}, Train AUC-PR: {train_auc_pr:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Prec: {val_prec:.4f}, Val Recall: {val_recall:.4f}, Val AUC-ROC: {val_auc_roc:.4f}, Val AUC-PR: {val_auc_pr:.4f}\")\n",
        "\n",
        "        # Print the current value of the trainable alpha and moving averages\n",
        "        if isinstance(loss_function, PGFLossTF):\n",
        "             print(f\"  PGFL Learned Alpha: {loss_function.alpha.numpy():.4f}, MC0: {loss_function.mc0.numpy():.4f}, MC1: {loss_function.mc1.numpy():.4f}\")\n",
        "\n",
        "\n",
        "        # --- Early Stopping Check (using validation loss) ---\n",
        "        if avg_val_loss < best_val_loss - early_stopping.min_delta:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            # Save current weights if validation loss improved\n",
        "            model.save_weights(model_weights_path)\n",
        "            # Save loss function trainable variables (alpha) and moving averages\n",
        "            np.save(loss_weights_path, [loss_function.alpha.numpy(), loss_function.mc0.numpy(), loss_function.mc1.numpy()])\n",
        "            #print(\"Saved model and PGFL loss parameters.\")\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= early_stopping.patience:\n",
        "                print(f\"Early stopping triggered based on validation loss after {epoch+1} epochs.\")\n",
        "                # Restore best weights if early stopping is triggered\n",
        "                if os.path.exists(model_weights_path):\n",
        "                    print(\"Restoring model weights from best validation epoch...\")\n",
        "                    model.load_weights(model_weights_path)\n",
        "                if os.path.exists(loss_weights_path):\n",
        "                    print(\"Restoring PGFL loss parameters from best validation epoch...\")\n",
        "                    best_loss_params = np.load(loss_weights_path)\n",
        "                    loss_function.alpha.assign(best_loss_params[0])\n",
        "                    loss_function.mc0.assign(best_loss_params[1])\n",
        "                    loss_function.mc1.assign(best_loss_params[2])\n",
        "                    print(f\"  Restored PGFL Params: Alpha={loss_function.alpha.numpy():.4f}, MC0={loss_function.mc0.numpy():.4f}, MC1={loss_function.mc1.numpy():.4f}\")\n",
        "\n",
        "                break # Exit the training loop\n",
        "\n",
        "    return history # Return the history dictionary\n"
      ],
      "metadata": {
        "id": "EtAL7mcLgNOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp2xqUM1faDQ",
        "outputId": "822a4b30-ae03-418e-e8b3-b884e3f571ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# --- 2. Data Loading from Google Drive ---\n",
        "# This function is now the sole method for loading data.\n",
        "def load_data_from_drive(file_path):\n",
        "    \"\"\"\n",
        "    Loads a dataset from a given file path.\n",
        "    Assumes the last column is the target and no header row in the CSV file.\n",
        "    Args:\n",
        "        file_path (str): The full path to the CSV file.\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded DataFrame.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: File not found at {file_path}.\")\n",
        "        return None\n",
        "\n",
        "    # Read CSV assuming with header. P\n",
        "    # Assuming the files are Excel (.xlsx) as per the main execution block\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "        # doing it for non avalanche datasets otherwise avalanceh datasets have headers\n",
        "        #df = pd.read_excel(file_path, header=None)\n",
        "\n",
        "        # Drop columns by name if they exist\n",
        "        df = df.drop(columns=['Date', 'Index'], errors='ignore')\n",
        "\n",
        "        print(f\"DataFrame after dropping 'Date' and 'Index' columns: {df.shape}\")\n",
        "        print(f\"Remaining columns: {df.columns.tolist()}\")\n",
        "\n",
        "        # Show class distribution of the assumed target (last column)\n",
        "        print(f\"Assuming the last column '{df.columns[-1]}' is the target column.\")\n",
        "        print(f\"Class distribution:\\n{df.iloc[:, -1].value_counts()}\")\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- 4. Loss Function Implementations for TensorFlow ---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bf98a1d"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement early stopping logic within the custom training loop to stop training when validation loss does not improve for a specified number of epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dc4f224"
      },
      "source": [
        "**Reasoning**:\n",
        "The `RuntimeError: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)` indicates that `tape.gradient()` is being called multiple times on the same non-persistent tape within the `train_step` function. This happens because I attempted to calculate gradients for `model.trainable_variables` and `loss_trainable_variables` separately within the same `with tf.GradientTape() as tape:` block.\n",
        "\n",
        "To fix this, I need to collect all variables for which gradients should be computed *before* calling `tape.gradient()`. Then, I will call `tape.gradient()` only once, passing the loss and the combined list of model and loss trainable variables.\n",
        "\n",
        "This approach ensures that the gradients are computed in a single pass over the tape, resolving the `RuntimeError` and allowing the training loop to proceed. The early stopping logic remains correctly implemented in the `custom_train_loop`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcmMydPRprEf"
      },
      "outputs": [],
      "source": [
        "class ClassBalancedLossTF(tf.keras.losses.Loss):\n",
        "    \"\"\"\n",
        "    Class Balanced Loss for Imbalanced Datasets in TensorFlow.\n",
        "    Re-weights the standard loss by the 'effective number of samples' for each class.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_majority, num_minority, beta=0.999, name=\"class_balanced_loss_tf\"):\n",
        "        super().__init__(name=name)\n",
        "        self.beta = tf.constant(beta, dtype=tf.float32)\n",
        "\n",
        "        # Calculate effective number of samples for each class\n",
        "        # Add a small epsilon to avoid division by zero in case num_samples is 0 or beta is 1\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "\n",
        "        effective_num_majority = (1.0 - tf.pow(self.beta, tf.cast(num_majority, tf.float32))) / (1.0 - self.beta + epsilon)\n",
        "        effective_num_minority = (1.0 - tf.pow(self.beta, tf.cast(num_minority, tf.float32))) / (1.0 - self.beta + epsilon)\n",
        "\n",
        "        # Calculate class-balanced weights\n",
        "        self.w0_cb = tf.constant(1.0, dtype=tf.float32) / effective_num_majority\n",
        "        self.w1_cb = tf.constant(1.0, dtype=tf.float32) / effective_num_minority\n",
        "\n",
        "        tf.print(f\"CB Loss Weights: w0 (majority)={self.w0_cb}, w1 (minority)={self.w1_cb}\")\n",
        "\n",
        "    def call(self, y_true, y_pred_logits):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred_logits = tf.cast(y_pred_logits, tf.float32)\n",
        "\n",
        "        # Calculate standard BCE\n",
        "        bce_unweighted = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred_logits)\n",
        "\n",
        "        # Apply class-balanced weights\n",
        "        cb_loss = tf.where(tf.equal(y_true, 1), bce_unweighted * self.w1_cb, bce_unweighted * self.w0_cb)\n",
        "\n",
        "        return tf.reduce_mean(cb_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSokBZmTp0WG"
      },
      "outputs": [],
      "source": [
        "class FocalLossTF(tf.keras.losses.Loss):\n",
        "    \"\"\"\n",
        "    Focal Loss for Imbalanced Datasets in TensorFlow.\n",
        "    Focuses training on hard, misclassified examples by down-weighting easy examples.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, name=\"focal_loss_tf\"):\n",
        "        super().__init__(name=name)\n",
        "        self.alpha = tf.constant(alpha, dtype=tf.float32)\n",
        "        self.gamma = tf.constant(gamma, dtype=tf.float32)\n",
        "\n",
        "    def call(self, y_true, y_pred_logits):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred_logits = tf.cast(y_pred_logits, tf.float32)\n",
        "\n",
        "        # Calculate standard BCE (log loss)\n",
        "        bce = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred_logits)\n",
        "\n",
        "        # Calculate probabilities\n",
        "        p = tf.sigmoid(y_pred_logits)\n",
        "\n",
        "        # p_t is the probability of the true class\n",
        "        p_t = y_true * p + (1 - y_true) * (1 - p)\n",
        "\n",
        "        # alpha_t is alpha for positive, 1-alpha for negative\n",
        "        alpha_t = y_true * self.alpha + (1 - y_true) * (1.0 - self.alpha)\n",
        "\n",
        "        # Modulating factor (1 - p_t)^gamma\n",
        "        modulating_factor = tf.pow(1.0 - p_t, self.gamma)\n",
        "\n",
        "        # Focal Loss: alpha_t * (1 - p_t)^gamma * BCE\n",
        "        focal_loss = alpha_t * modulating_factor * bce\n",
        "        return tf.reduce_mean(focal_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmCCiFLjsedr"
      },
      "outputs": [],
      "source": [
        "# Define the plots save directory again as it's needed for the print statement\n",
        "plots_save_dir = os.path.join(GOOGLE_DRIVE_PATH, 'training_plots')\n",
        "\n",
        "# print(\"Manually reviewing the training history plots saved in Google Drive.\")\n",
        "# print(f\"Looking for plots named like '*AMRL_*_plot.png' in {plots_save_dir} for the AMRL loss.\")\n",
        "# print(\"Specifically checking the plots for:\")\n",
        "# print(\"1. Training and Validation Loss: How did they change over epochs? Did they converge? Was there overfitting?\")\n",
        "# print(\"2. Training and Validation Accuracy, Precision, Recall, AUC-ROC, AUC-PR: What were the trends for these metrics?\")\n",
        "# print(\"3. Note the epoch where early stopping occurred (indicated by the training output) and the best validation loss.\")\n",
        "# print(\"4. Examine the learned AMRL parameters printed per epoch during the custom training loop to see their evolution.\")\n",
        "\n",
        "# Note: Accessing external files (like plots in Google Drive) for analysis programmatically\n",
        "# in this environment without explicit file reading/display code is not straightforward.\n",
        "# The analysis step relies on manual inspection of the generated files and the printed output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f69921f8"
      },
      "source": [
        "## Define discriminator model\n",
        "\n",
        "### Subtask:\n",
        "Create a new TensorFlow/Keras model for the discriminator network. This network will take the model's output (logits or probabilities) and potentially the input features as input and try to distinguish between real (true label) and fake (predicted label) samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "665b58a9"
      },
      "source": [
        "## Define gan loss function\n",
        "\n",
        "### Subtask:\n",
        "Implement the adversarial loss function. This will likely involve combining the standard classification loss (like BCE or one of the imbalanced losses) with the discriminator's loss. The generator (your current model) will try to minimize the loss from the discriminator, while the discriminator will try to maximize it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5bf5d10"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the PGFL loss function class as requested in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a624e59"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the GAN-based loss function components within the custom training loop structure, as defining a single `tf.keras.losses.Loss` class for GANs with separate generator and discriminator steps is not standard.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e50f6ede"
      },
      "source": [
        "**Reasoning**:\n",
        "Integrate the GAN training loop into the main execution block to train the model using the GAN-based approach for comparison with other loss functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "f08b2c8b",
        "outputId": "b1809917-f4aa-40ad-8e06-331226b6ed8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scanning for XLSX files in: /content/drive/MyDrive/1. Trial/\n",
            "Plots will be saved to: /content/drive/MyDrive/1. Trial/training_plots\n",
            "Results will be saved to: /content/drive/MyDrive/1. Trial/text files\n",
            "\n",
            "############################################################\n",
            "Processing Dataset: 206_output_final_modified_less_columns.xlsx\n",
            "############################################################\n",
            "DataFrame shape after initial load: (4713, 20)\n",
            "        Date  Station_Code  Maximum_Temperature  Minimum_Temperature  \\\n",
            "0 1999-11-01           NaN                  NaN                 -5.0   \n",
            "1 1999-11-02           NaN                 16.5                 -7.0   \n",
            "2 1999-11-03           NaN                 15.5                 -5.0   \n",
            "3 1999-11-04           NaN                 15.5                  0.0   \n",
            "4 1999-11-05           NaN                  2.0                 -1.0   \n",
            "\n",
            "   Average_Temperature  Dry_Temperature  Snow_Temperature  \\\n",
            "0                  NaN             -3.0               NaN   \n",
            "1                  7.8             -2.0               NaN   \n",
            "2                  9.5              0.0               NaN   \n",
            "3                  7.5              2.0               NaN   \n",
            "4                  1.7              0.0              -1.0   \n",
            "\n",
            "   Ambient_Temperature_Trend_In_Last_24_Hours  \\\n",
            "0                                         NaN   \n",
            "1                                         1.0   \n",
            "2                                         2.0   \n",
            "3                                         2.0   \n",
            "4                                        -2.0   \n",
            "\n",
            "   Ambient_Temperature_Trend_In_Last_48_Hours  Cloud_Amount  Snow_Penetration  \\\n",
            "0                                         NaN           0.0               NaN   \n",
            "1                                         NaN           0.0               NaN   \n",
            "2                                         3.0           4.0               NaN   \n",
            "3                                         4.0           8.0               1.0   \n",
            "4                                         0.0           8.0               6.0   \n",
            "\n",
            "   Average_Wind_Speed  Standing_Snow  Snow_Fall_In_Last_24_Hours  \\\n",
            "0                 NaN            NaN                         NaN   \n",
            "1                3.42            NaN                         0.0   \n",
            "2                3.18            NaN                         0.0   \n",
            "3                4.81            1.0                         1.0   \n",
            "4                1.16            6.0                         8.0   \n",
            "\n",
            "   Snow_Fall_In_Last_48_Hours  Snow_Fall_In_Last_72_Hours  Sunshine  \\\n",
            "0                         NaN                         NaN       NaN   \n",
            "1                         NaN                         NaN       6.0   \n",
            "2                         0.0                         NaN       8.5   \n",
            "3                         1.0                         1.0       4.0   \n",
            "4                         9.0                         9.0       0.0   \n",
            "\n",
            "   Drift_Index  Drift_Index_Square  Avalanche_Occurences  \n",
            "0          NaN                 NaN                     0  \n",
            "1          0.0                 NaN                     0  \n",
            "2          0.0                 0.0                     0  \n",
            "3          4.8                 4.8                     0  \n",
            "4          9.3                14.1                     0  \n",
            "\n",
            "Splitting data into train, validation, and test sets...\n",
            "Train set size: 2280 (Minority: 434)\n",
            "Validation set size: 326 (Minority: 62)\n",
            "Test set size: 652 (Minority: 124)\n",
            "Saving class ratios to: /content/drive/MyDrive/1. Trial/text files/206_output_final_modified_less_columns.xlsx_class_ratios.txt\n",
            "Input dimension for the model: 13\n",
            "\n",
            "--------------------------------------------------------\n",
            "Training 206_output_final_modified_less_columns.xlsx with AMRL Loss\n",
            "--------------------------------------------------------\n",
            "Margin Loss Parameters (Initial Values):\n",
            "  BCE Weights: w1_bce (minority) = 0.8096, w0_bce (majority) = 0.1904\n",
            "  Margins: m1 (pos) = 1.0, m0 (neg) = -1.0\n",
            "  Lambdas: lambda1 (pos) = 2.0, lambda0 (neg) = 1.0\n",
            "  Betas: beta1 (pos) = 2, beta0 = 1\n",
            "\n",
            "Starting custom training loop for AMRL...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 1.0562, Train Acc: 0.7925, Train Prec: 0.4396, Train Recall: 0.3272, Train AUC-ROC: 0.7382, Train AUC-PR: 0.4069\n",
            "Val Loss: 0.5532, Val Acc: 0.7485, Val Prec: 0.3958, Val Recall: 0.6129, Val AUC-ROC: 0.7955, Val AUC-PR: 0.5142\n",
            "  AMRL Learned Params: m1=0.6393, m0=-0.6754, lambda1=1.6519, lambda0=0.7145\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.4657, Train Acc: 0.8004, Train Prec: 0.4733, Train Recall: 0.4286, Train AUC-ROC: 0.7671, Train AUC-PR: 0.4622\n",
            "Val Loss: 0.2946, Val Acc: 0.7853, Val Prec: 0.4524, Val Recall: 0.6129, Val AUC-ROC: 0.8019, Val AUC-PR: 0.5227\n",
            "  AMRL Learned Params: m1=0.2870, m0=-0.3307, lambda1=1.3776, lambda0=0.3872\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.2417, Train Acc: 0.7741, Train Prec: 0.4268, Train Recall: 0.5438, Train AUC-ROC: 0.7856, Train AUC-PR: 0.4664\n",
            "Val Loss: 0.1992, Val Acc: 0.6810, Val Prec: 0.3478, Val Recall: 0.7742, Val AUC-ROC: 0.8173, Val AUC-PR: 0.5471\n",
            "  AMRL Learned Params: m1=0.0593, m0=-0.1185, lambda1=1.2464, lambda0=0.0444\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: -9.1405, Train Acc: 0.3974, Train Prec: 0.2305, Train Recall: 0.9263, Train AUC-ROC: 0.5906, Train AUC-PR: 0.2191\n",
            "Val Loss: -64.1499, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  AMRL Learned Params: m1=0.0285, m0=-0.3023, lambda1=1.2287, lambda0=-0.9056\n",
            "Stopping training: Train Loss became negative at epoch 4.\n",
            "Restoring model weights from previous epoch...\n",
            "Restoring loss parameters from previous epoch...\n",
            "  Restored AMRL Params: m1=0.0593, m0=-0.1185, lambda1=1.2464, lambda0=0.0444\n",
            "Custom training loop finished.\n",
            "\n",
            "Plotting training history...\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_AMRL_loss_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_AMRL_accuracy_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_AMRL_precision_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_AMRL_recall_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_AMRL_auc_roc_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_AMRL_auc_pr_plot.png\n",
            "\n",
            "Evaluating on the Test Set...\n",
            "Train class distribution: [1846  434]\n",
            "Val class distribution: [264  62]\n",
            "Test class distribution: [528 124]\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step\n",
            "Dataset: 206_output_final_modified_less_columns.xlsx\n",
            "Loss_Type: AMRL\n",
            "Epochs: 4\n",
            "Batch_Size: 5\n",
            "Positive: 124\n",
            "Negative: 528\n",
            "TP: 92\n",
            "TN: 374\n",
            "FP: 154\n",
            "FN: 32\n",
            "Accuracy: 0.8100\n",
            "Precision: 0.5200\n",
            "Recall: 0.3500\n",
            "AUC-ROC: 0.8100\n",
            "AUC-PR: 0.4700\n",
            "Specificity: 0.7083\n",
            "G-Mean: 0.7200\n",
            "Balanced_Accuracy: 0.7300\n",
            "KSS_TSS: 0.4500\n",
            "HSS: 0.3300\n",
            "PSS: 0.4500\n",
            "FAR: 0.2900\n",
            "bias: 1.9800\n",
            "pod: 0.7400\n",
            "f1: 0.5000\n",
            "Learned_M_POS: 0.059268441051244736\n",
            "Learned_M_NEG: -0.118548683822155\n",
            "Learned_LAMBDA_POS: 1.2463960647583008\n",
            "Learned_LAMBDA_NEG: 0.04435805231332779\n",
            "\n",
            "--------------------------------------------------------\n",
            "Training 206_output_final_modified_less_columns.xlsx with BCE Loss\n",
            "--------------------------------------------------------\n",
            "Standard Binary Crossentropy Loss\n",
            "\n",
            "Starting model.fit training...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8116 - auc_pr: 0.2547 - auc_roc: 0.5447 - loss: 0.4753 - precision: 0.3854 - recall: 0.0339 - val_accuracy: 0.8160 - val_auc_pr: 0.3842 - val_auc_roc: 0.6213 - val_loss: 0.4268 - val_precision: 0.6250 - val_recall: 0.0806\n",
            "Epoch 2/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8032 - auc_pr: 0.3273 - auc_roc: 0.5755 - loss: 0.4495 - precision: 0.6340 - recall: 0.0766 - val_accuracy: 0.8098 - val_auc_pr: 0.2675 - val_auc_roc: 0.5504 - val_loss: 0.4225 - val_precision: 0.5000 - val_recall: 0.0323\n",
            "Epoch 3/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8066 - auc_pr: 0.3137 - auc_roc: 0.5740 - loss: 0.4087 - precision: 0.5567 - recall: 0.0459 - val_accuracy: 0.8160 - val_auc_pr: 0.3507 - val_auc_roc: 0.5952 - val_loss: 0.4120 - val_precision: 0.6667 - val_recall: 0.0645\n",
            "Epoch 4/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8115 - auc_pr: 0.3091 - auc_roc: 0.5739 - loss: 0.4117 - precision: 0.5510 - recall: 0.0641 - val_accuracy: 0.8190 - val_auc_pr: 0.3514 - val_auc_roc: 0.6034 - val_loss: 0.4131 - val_precision: 0.7143 - val_recall: 0.0806\n",
            "Epoch 5/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8198 - auc_pr: 0.3739 - auc_roc: 0.6013 - loss: 0.4149 - precision: 0.7851 - recall: 0.1042 - val_accuracy: 0.8282 - val_auc_pr: 0.3663 - val_auc_roc: 0.6172 - val_loss: 0.4107 - val_precision: 0.8000 - val_recall: 0.1290\n",
            "Epoch 6/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8175 - auc_pr: 0.3083 - auc_roc: 0.5747 - loss: 0.4078 - precision: 0.6107 - recall: 0.0590 - val_accuracy: 0.8190 - val_auc_pr: 0.3624 - val_auc_roc: 0.6076 - val_loss: 0.4020 - val_precision: 0.7143 - val_recall: 0.0806\n",
            "Epoch 7/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8151 - auc_pr: 0.3595 - auc_roc: 0.5854 - loss: 0.4243 - precision: 0.7555 - recall: 0.0823 - val_accuracy: 0.8160 - val_auc_pr: 0.3398 - val_auc_roc: 0.5794 - val_loss: 0.4063 - val_precision: 0.6667 - val_recall: 0.0645\n",
            "Epoch 8/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8224 - auc_pr: 0.3352 - auc_roc: 0.5835 - loss: 0.3916 - precision: 0.6611 - recall: 0.0718 - val_accuracy: 0.8160 - val_auc_pr: 0.3578 - val_auc_roc: 0.6085 - val_loss: 0.4031 - val_precision: 0.6000 - val_recall: 0.0968\n",
            "Epoch 9/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8199 - auc_pr: 0.3365 - auc_roc: 0.5861 - loss: 0.3834 - precision: 0.6648 - recall: 0.0923 - val_accuracy: 0.8129 - val_auc_pr: 0.2977 - val_auc_roc: 0.5519 - val_loss: 0.4161 - val_precision: 0.6000 - val_recall: 0.0484\n",
            "Epoch 10/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8184 - auc_pr: 0.3080 - auc_roc: 0.5742 - loss: 0.4088 - precision: 0.6022 - recall: 0.0519 - val_accuracy: 0.8252 - val_auc_pr: 0.4111 - val_auc_roc: 0.6458 - val_loss: 0.4095 - val_precision: 0.6316 - val_recall: 0.1935\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "model.fit training finished.\n",
            "\n",
            "Plotting training history...\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_BCE_accuracy_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_BCE_auc_pr_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_BCE_auc_roc_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_BCE_loss_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_BCE_precision_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_BCE_recall_plot.png\n",
            "\n",
            "Evaluating on the Test Set...\n",
            "Train class distribution: [1846  434]\n",
            "Val class distribution: [264  62]\n",
            "Test class distribution: [528 124]\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step\n",
            "Dataset: 206_output_final_modified_less_columns.xlsx\n",
            "Loss_Type: BCE\n",
            "Epochs: 10\n",
            "Batch_Size: 5\n",
            "Positive: 124\n",
            "Negative: 528\n",
            "TP: 24\n",
            "TN: 514\n",
            "FP: 14\n",
            "FN: 100\n",
            "Accuracy: 0.8200\n",
            "Precision: 0.6700\n",
            "Recall: 0.0600\n",
            "AUC-ROC: 0.8100\n",
            "AUC-PR: 0.4900\n",
            "Specificity: 0.9735\n",
            "G-Mean: 0.4300\n",
            "Balanced_Accuracy: 0.5800\n",
            "KSS_TSS: 0.1700\n",
            "HSS: 0.2300\n",
            "PSS: 0.1700\n",
            "FAR: 0.0300\n",
            "bias: 0.3100\n",
            "pod: 0.1900\n",
            "f1: 0.3000\n",
            "\n",
            "--------------------------------------------------------\n",
            "Training 206_output_final_modified_less_columns.xlsx with FOCAL Loss\n",
            "--------------------------------------------------------\n",
            "Focal Loss Parameters: alpha=0.8096, gamma=2.0000\n",
            "\n",
            "Starting model.fit training...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7871 - auc_pr: 0.3239 - auc_roc: 0.6539 - loss: 0.0532 - precision: 0.4029 - recall: 0.1740 - val_accuracy: 0.8344 - val_auc_pr: 0.4909 - val_auc_roc: 0.7556 - val_loss: 0.0438 - val_precision: 0.6667 - val_recall: 0.2581\n",
            "Epoch 2/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8180 - auc_pr: 0.3708 - auc_roc: 0.6992 - loss: 0.0462 - precision: 0.4863 - recall: 0.1840 - val_accuracy: 0.8282 - val_auc_pr: 0.4813 - val_auc_roc: 0.7655 - val_loss: 0.0446 - val_precision: 0.6875 - val_recall: 0.1774\n",
            "Epoch 3/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8186 - auc_pr: 0.3955 - auc_roc: 0.7092 - loss: 0.0466 - precision: 0.5834 - recall: 0.1663 - val_accuracy: 0.8129 - val_auc_pr: 0.5055 - val_auc_roc: 0.7531 - val_loss: 0.0453 - val_precision: 0.6000 - val_recall: 0.0484\n",
            "Epoch 4/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8200 - auc_pr: 0.4462 - auc_roc: 0.7345 - loss: 0.0450 - precision: 0.6249 - recall: 0.1694 - val_accuracy: 0.8282 - val_auc_pr: 0.5034 - val_auc_roc: 0.7703 - val_loss: 0.0454 - val_precision: 0.8000 - val_recall: 0.1290\n",
            "Epoch 5/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8296 - auc_pr: 0.3997 - auc_roc: 0.6995 - loss: 0.0455 - precision: 0.6009 - recall: 0.1549 - val_accuracy: 0.8405 - val_auc_pr: 0.4705 - val_auc_roc: 0.7503 - val_loss: 0.0459 - val_precision: 0.7500 - val_recall: 0.2419\n",
            "Epoch 6/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8272 - auc_pr: 0.4610 - auc_roc: 0.7321 - loss: 0.0445 - precision: 0.6057 - recall: 0.2641 - val_accuracy: 0.8282 - val_auc_pr: 0.4987 - val_auc_roc: 0.7596 - val_loss: 0.0464 - val_precision: 0.7143 - val_recall: 0.1613\n",
            "Epoch 7/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8212 - auc_pr: 0.4886 - auc_roc: 0.7669 - loss: 0.0426 - precision: 0.5974 - recall: 0.2274 - val_accuracy: 0.8252 - val_auc_pr: 0.4906 - val_auc_roc: 0.7730 - val_loss: 0.0447 - val_precision: 0.6471 - val_recall: 0.1774\n",
            "Epoch 8/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8235 - auc_pr: 0.5024 - auc_roc: 0.7717 - loss: 0.0433 - precision: 0.6306 - recall: 0.2370 - val_accuracy: 0.8252 - val_auc_pr: 0.4878 - val_auc_roc: 0.7645 - val_loss: 0.0462 - val_precision: 0.6923 - val_recall: 0.1452\n",
            "Epoch 9/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8356 - auc_pr: 0.4906 - auc_roc: 0.7578 - loss: 0.0410 - precision: 0.6128 - recall: 0.2190 - val_accuracy: 0.8160 - val_auc_pr: 0.4441 - val_auc_roc: 0.7594 - val_loss: 0.0465 - val_precision: 0.5625 - val_recall: 0.1452\n",
            "Epoch 10/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8208 - auc_pr: 0.4261 - auc_roc: 0.7283 - loss: 0.0457 - precision: 0.5687 - recall: 0.1872 - val_accuracy: 0.8221 - val_auc_pr: 0.4630 - val_auc_roc: 0.7517 - val_loss: 0.0459 - val_precision: 0.5769 - val_recall: 0.2419\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "model.fit training finished.\n",
            "\n",
            "Plotting training history...\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_FOCAL_accuracy_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_FOCAL_auc_pr_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_FOCAL_auc_roc_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_FOCAL_loss_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_FOCAL_precision_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_FOCAL_recall_plot.png\n",
            "\n",
            "Evaluating on the Test Set...\n",
            "Train class distribution: [1846  434]\n",
            "Val class distribution: [264  62]\n",
            "Test class distribution: [528 124]\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step\n",
            "Dataset: 206_output_final_modified_less_columns.xlsx\n",
            "Loss_Type: FOCAL\n",
            "Epochs: 10\n",
            "Batch_Size: 5\n",
            "Positive: 124\n",
            "Negative: 528\n",
            "TP: 93\n",
            "TN: 370\n",
            "FP: 158\n",
            "FN: 31\n",
            "Accuracy: 0.8200\n",
            "Precision: 0.6300\n",
            "Recall: 0.1800\n",
            "AUC-ROC: 0.8000\n",
            "AUC-PR: 0.4700\n",
            "Specificity: 0.7008\n",
            "G-Mean: 0.7200\n",
            "Balanced_Accuracy: 0.7300\n",
            "KSS_TSS: 0.4500\n",
            "HSS: 0.3200\n",
            "PSS: 0.4500\n",
            "FAR: 0.3000\n",
            "bias: 2.0200\n",
            "pod: 0.7500\n",
            "f1: 0.5000\n",
            "\n",
            "--------------------------------------------------------\n",
            "Training 206_output_final_modified_less_columns.xlsx with CB Loss\n",
            "--------------------------------------------------------\n",
            "Class Balanced Loss Parameters: beta=0.9990\n",
            "CB Loss Weights: w0 (majority)=0.0011873646872118115, w1 (minority)=0.0028393433894962072\n",
            "\n",
            "Starting model.fit training...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7994 - auc_pr: 0.2987 - auc_roc: 0.5925 - loss: 9.2767e-04 - precision: 0.4097 - recall: 0.1378 - val_accuracy: 0.8374 - val_auc_pr: 0.4335 - val_auc_roc: 0.6837 - val_loss: 8.2246e-04 - val_precision: 0.6800 - val_recall: 0.2742\n",
            "Epoch 2/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8125 - auc_pr: 0.3701 - auc_roc: 0.6578 - loss: 8.1622e-04 - precision: 0.4927 - recall: 0.2239 - val_accuracy: 0.8313 - val_auc_pr: 0.4701 - val_auc_roc: 0.7057 - val_loss: 8.0783e-04 - val_precision: 0.6400 - val_recall: 0.2581\n",
            "Epoch 3/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8241 - auc_pr: 0.3642 - auc_roc: 0.6783 - loss: 7.8615e-04 - precision: 0.4962 - recall: 0.2140 - val_accuracy: 0.8405 - val_auc_pr: 0.4650 - val_auc_roc: 0.7168 - val_loss: 7.9858e-04 - val_precision: 0.6250 - val_recall: 0.4032\n",
            "Epoch 4/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7991 - auc_pr: 0.4008 - auc_roc: 0.6742 - loss: 8.5113e-04 - precision: 0.5237 - recall: 0.2971 - val_accuracy: 0.8466 - val_auc_pr: 0.4780 - val_auc_roc: 0.7149 - val_loss: 7.9750e-04 - val_precision: 0.6875 - val_recall: 0.3548\n",
            "Epoch 5/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8241 - auc_pr: 0.4569 - auc_roc: 0.7203 - loss: 7.4985e-04 - precision: 0.5801 - recall: 0.3490 - val_accuracy: 0.8313 - val_auc_pr: 0.4585 - val_auc_roc: 0.7037 - val_loss: 8.0885e-04 - val_precision: 0.6522 - val_recall: 0.2419\n",
            "Epoch 6/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8147 - auc_pr: 0.3876 - auc_roc: 0.6617 - loss: 8.0732e-04 - precision: 0.5408 - recall: 0.2247 - val_accuracy: 0.8405 - val_auc_pr: 0.4575 - val_auc_roc: 0.7118 - val_loss: 8.0480e-04 - val_precision: 0.6250 - val_recall: 0.4032\n",
            "Epoch 7/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8126 - auc_pr: 0.4169 - auc_roc: 0.6893 - loss: 7.8335e-04 - precision: 0.5368 - recall: 0.2932 - val_accuracy: 0.8282 - val_auc_pr: 0.4441 - val_auc_roc: 0.6862 - val_loss: 8.1876e-04 - val_precision: 0.6071 - val_recall: 0.2742\n",
            "Epoch 8/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8307 - auc_pr: 0.4288 - auc_roc: 0.6983 - loss: 7.9312e-04 - precision: 0.5875 - recall: 0.2872 - val_accuracy: 0.8313 - val_auc_pr: 0.4455 - val_auc_roc: 0.6941 - val_loss: 8.2232e-04 - val_precision: 0.6207 - val_recall: 0.2903\n",
            "Epoch 9/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8220 - auc_pr: 0.3979 - auc_roc: 0.6693 - loss: 8.1517e-04 - precision: 0.5897 - recall: 0.2660 - val_accuracy: 0.8405 - val_auc_pr: 0.4797 - val_auc_roc: 0.7316 - val_loss: 8.1092e-04 - val_precision: 0.7083 - val_recall: 0.2742\n",
            "Epoch 10/10\n",
            "\u001b[1m456/456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - auc_pr: 0.3909 - auc_roc: 0.6777 - loss: 7.6114e-04 - precision: 0.5545 - recall: 0.2173 - val_accuracy: 0.8374 - val_auc_pr: 0.4520 - val_auc_roc: 0.7088 - val_loss: 8.0781e-04 - val_precision: 0.6216 - val_recall: 0.3710\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "model.fit training finished.\n",
            "\n",
            "Plotting training history...\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_CB_accuracy_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_CB_auc_pr_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_CB_auc_roc_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_CB_loss_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_CB_precision_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_CB_recall_plot.png\n",
            "\n",
            "Evaluating on the Test Set...\n",
            "Train class distribution: [1846  434]\n",
            "Val class distribution: [264  62]\n",
            "Test class distribution: [528 124]\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step\n",
            "Dataset: 206_output_final_modified_less_columns.xlsx\n",
            "Loss_Type: CB\n",
            "Epochs: 10\n",
            "Batch_Size: 5\n",
            "Positive: 124\n",
            "Negative: 528\n",
            "TP: 59\n",
            "TN: 460\n",
            "FP: 68\n",
            "FN: 65\n",
            "Accuracy: 0.8200\n",
            "Precision: 0.5400\n",
            "Recall: 0.2600\n",
            "AUC-ROC: 0.8000\n",
            "AUC-PR: 0.4800\n",
            "Specificity: 0.8712\n",
            "G-Mean: 0.6400\n",
            "Balanced_Accuracy: 0.6700\n",
            "KSS_TSS: 0.3500\n",
            "HSS: 0.3400\n",
            "PSS: 0.3500\n",
            "FAR: 0.1300\n",
            "bias: 1.0200\n",
            "pod: 0.4800\n",
            "f1: 0.4700\n",
            "\n",
            "--------------------------------------------------------\n",
            "Training 206_output_final_modified_less_columns.xlsx with PGFL Loss\n",
            "--------------------------------------------------------\n",
            "PGFL Loss Parameters (Initial Values):\n",
            "  Gamma: 2.0000\n",
            "  Initial Alpha (Minority Weight): 0.8096\n",
            "\n",
            "Starting custom training loop for PGFL...\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: -5.2993, Train Acc: 0.3553, Train Prec: 0.2176, Train Recall: 0.9194, Train AUC-ROC: 0.5601, Train AUC-PR: 0.2067\n",
            "Val Loss: -44.1994, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 1.4167, MC0: 0.5511, MC1: 0.9825\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: -575.3597, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -1627.6294, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 1.9541, MC0: 0.5511, MC1: 1.0000\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: -5070.6680, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -9917.6484, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 2.4415, MC0: 0.5511, MC1: 1.0000\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: -21094.1133, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -34384.2617, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 2.9139, MC0: 0.5511, MC1: 1.0000\n",
            "\n",
            "Epoch 5/10\n",
            "Train Loss: -60468.9258, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -88761.4609, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 3.3794, MC0: 0.5511, MC1: 1.0000\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: -140658.0625, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -191818.1719, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 3.8412, MC0: 0.5511, MC1: 1.0000\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: -283280.5938, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -367266.4688, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 4.3009, MC0: 0.5511, MC1: 1.0000\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: -516108.0938, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -645444.9375, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 4.7593, MC0: 0.5511, MC1: 1.0000\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: -874801.0000, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -1061564.5000, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 5.2169, MC0: 0.5511, MC1: 1.0000\n",
            "\n",
            "Epoch 10/10\n",
            "Train Loss: -1389212.6250, Train Acc: 0.1904, Train Prec: 0.1904, Train Recall: 1.0000, Train AUC-ROC: 0.5000, Train AUC-PR: 0.1904\n",
            "Val Loss: -1656428.7500, Val Acc: 0.1902, Val Prec: 0.1902, Val Recall: 1.0000, Val AUC-ROC: 0.5000, Val AUC-PR: 0.1902\n",
            "  PGFL Learned Alpha: 5.6740, MC0: 0.5511, MC1: 1.0000\n",
            "Custom training loop finished.\n",
            "\n",
            "Plotting training history...\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_PGFL_loss_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_PGFL_accuracy_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_PGFL_precision_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_PGFL_recall_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_PGFL_auc_roc_plot.png\n",
            "Saved plot to: /content/drive/MyDrive/1. Trial/training_plots/206_output_final_modified_less_columns_PGFL_auc_pr_plot.png\n",
            "\n",
            "Evaluating on the Test Set...\n",
            "Train class distribution: [1846  434]\n",
            "Val class distribution: [264  62]\n",
            "Test class distribution: [528 124]\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step\n",
            "\u001b[1m131/131\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step\n",
            "Dataset: 206_output_final_modified_less_columns.xlsx\n",
            "Loss_Type: PGFL\n",
            "Epochs: 10\n",
            "Batch_Size: 5\n",
            "Positive: 124\n",
            "Negative: 528\n",
            "TP: 124\n",
            "TN: 0\n",
            "FP: 528\n",
            "FN: 0\n",
            "Accuracy: 0.1900\n",
            "Precision: 0.1900\n",
            "Recall: 1.0000\n",
            "AUC-ROC: 0.2700\n",
            "AUC-PR: 0.1300\n",
            "Specificity: 0.0000\n",
            "G-Mean: 0.0000\n",
            "Balanced_Accuracy: 0.5000\n",
            "KSS_TSS: 0.0000\n",
            "HSS: 0.0000\n",
            "PSS: 0.0000\n",
            "FAR: 1.0000\n",
            "bias: 5.2600\n",
            "pod: 1.0000\n",
            "f1: 0.3200\n",
            "Learned_Alpha: 5.673991680145264\n",
            "Final_MC0: 0.5511122345924377\n",
            "Final_MC1: 0.9999970197677612\n",
            "\n",
            "--------------------------------------------------------\n",
            "Training 206_output_final_modified_less_columns.xlsx with GAN Loss\n",
            "--------------------------------------------------------\n",
            "GAN Loss Parameters:\n",
            "  GAN Lambda (Adversarial Loss Weight): 0.1000\n",
            "\n",
            "Starting custom training loop for GAN...\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'binary_accuracy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3081397320.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting custom training loop for GAN...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0mearly_stopping_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEARLY_STOPPING_PATIENCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIN_DELTA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 history = custom_train_loop_gan(model, discriminator_model, optimizer, discriminator_optimizer,\n\u001b[0m\u001b[1;32m    429\u001b[0m                                                 \u001b[0mclassification_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Use val_dataset_inner for validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                                 NUM_EPOCHS, early_stopping_callback, CLIP_NORM, GAN_LAMBDA)\n",
            "\u001b[0;32m/tmp/ipython-input-4120099163.py\u001b[0m in \u001b[0;36mcustom_train_loop_gan\u001b[0;34m(generator, discriminator, generator_optimizer, discriminator_optimizer, classification_loss_fn, train_dataset, val_dataset, epochs, early_stopping, clip_norm, gan_lambda)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Reset metrics at the start of each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'binary_accuracy'"
          ]
        }
      ],
      "source": [
        "# Modify the main execution block to include 'GAN' in the comparison\n",
        "\n",
        "# Define a function for model initialization\n",
        "def initialize_model(input_dim, loss_type, num_majority_train, num_minority_train):\n",
        "    model = SimpleMLP_TF(input_dim)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # Optimizer for the main model (Generator)\n",
        "\n",
        "    discriminator_model = None # Discriminator is only needed for GAN loss\n",
        "    discriminator_optimizer = None # Discriminator optimizer is only needed for GAN loss\n",
        "\n",
        "    minority_loss_weight = None # Trainable weight for Meta-Learning\n",
        "    meta_optimizer = None # Optimizer for Meta-Learning weight\n",
        "\n",
        "    loss_function = None # Classification loss function (used directly or as base for GAN/Meta-Learning)\n",
        "\n",
        "    if loss_type == 'AMRL':\n",
        "        w1_bce_amrl = num_majority_train / (num_minority_train + num_majority_train)\n",
        "        w0_bce_amrl = num_minority_train / (num_minority_train + num_majority_train)\n",
        "        loss_function = AMRLLossTF(w1 = w1_bce_amrl, w0 = w0_bce_amrl, m1_init = M_POS_INIT, m0_init = M_NEG_INIT,\n",
        "                                  lambda1_init=LAMBDA_POS_INIT, lambda0_init = LAMBDA_NEG_INIT,\n",
        "                                  beta1 = BETA_POS_INIT, beta0 = BETA_NEG_INIT)\n",
        "    elif loss_type == 'PGFL':\n",
        "        alpha_init_pgfl = num_majority_train / (num_majority_train + num_minority_train)\n",
        "        loss_function = PGFLossTF(num_majority=num_majority_train, num_minority=num_minority_train,\n",
        "                                  gamma=gamma_pgfl, alpha_init=alpha_init_pgfl)\n",
        "    elif loss_type == 'GAN':\n",
        "        classification_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        # Fix: Directly use input_dim to initialize Discriminator\n",
        "        discriminator_model = Discriminator(input_dim_X=input_dim, input_dim_Y=1)\n",
        "        discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # Separate optimizer for discriminator\n",
        "        loss_function = classification_loss_fn # Use base classification loss for GAN generator metrics tracking\n",
        "\n",
        "    elif loss_type in ['BCE', 'FOCAL', 'CB']:\n",
        "        metrics_list = [\n",
        "            BinaryAccuracy(name = 'accuracy', threshold = 0.5),\n",
        "            Precision(name = 'precision', thresholds = 0.5),\n",
        "            Recall(name = 'recall', thresholds = 0.5),\n",
        "            AUC(name = 'auc_roc'),\n",
        "            AUC(curve = 'PR', name ='auc_pr')\n",
        "        ]\n",
        "        if loss_type == 'BCE':\n",
        "            loss_function = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
        "        elif loss_type == 'FOCAL':\n",
        "            alpha_focal = num_majority_train / (num_minority_train + num_minority_train)\n",
        "            gamma_focal = 2.0\n",
        "            loss_function = FocalLossTF(alpha = alpha_focal, gamma = gamma_focal)\n",
        "        elif loss_type == 'CB':\n",
        "            beta_cb = 0.999\n",
        "            loss_function = ClassBalancedLossTF(num_majority = num_majority_train, num_minority = num_minority_train, beta = beta_cb)\n",
        "\n",
        "        # Compile the model for Keras's fit method\n",
        "        model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics_list)\n",
        "\n",
        "\n",
        "    return model, optimizer, loss_function, discriminator_model, discriminator_optimizer\n",
        "\n",
        "\n",
        "# Define a function for training the model\n",
        "def train_model(model, optimizer, loss_function, discriminator_model, discriminator_optimizer,\n",
        "                train_dataset, val_dataset, epochs, early_stopping_callback, clip_norm, loss_type):\n",
        "    history = None\n",
        "    if loss_type == 'AMRL':\n",
        "        print(\"\\nStarting custom training loop for AMRL...\")\n",
        "        history = custom_train_loop(model, loss_function, optimizer, train_dataset, val_dataset, epochs, early_stopping_callback, clip_norm)\n",
        "        print(\"Custom training loop finished.\")\n",
        "    elif loss_type == 'PGFL':\n",
        "        print(\"\\nStarting custom training loop for PGFL...\")\n",
        "        history = custom_train_loop_pgfl(model, loss_function, optimizer, train_dataset, val_dataset, epochs, early_stopping_callback, CLIP_NORM)\n",
        "        print(\"Custom training loop finished.\")\n",
        "    elif loss_type == 'GAN':\n",
        "         print(\"\\nStarting custom training loop for GAN...\")\n",
        "         # For GAN, the base classification loss is typically BCE for the generator\n",
        "         classification_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "         history = custom_train_loop_gan(model, discriminator_model, optimizer, discriminator_optimizer,\n",
        "                                                classification_loss_fn, train_dataset, val_dataset,\n",
        "                                                epochs, early_stopping_callback, CLIP_NORM, GAN_LAMBDA)\n",
        "         print(\"Custom training loop finished.\")\n",
        "    elif loss_type in ['BCE', 'FOCAL', 'CB']:\n",
        "        print(\"\\nStarting model.fit training...\")\n",
        "        # The model is already compiled in initialize_model for these loss types\n",
        "        history = model.fit(train_dataset.unbatch().map(lambda x, y: (x, y)).batch(BATCH_SIZE), # Re-batch for model.fit\n",
        "                            epochs=epochs,\n",
        "                            validation_data=val_dataset.unbatch().map(lambda x, y: (x, y)).batch(BATCH_SIZE), # Re-batch for model.fit\n",
        "                            callbacks=[early_stopping_callback],\n",
        "                            verbose=1)\n",
        "        history = history.history\n",
        "        print(\"model.fit training finished.\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "# Define a function for evaluating the model and collecting results\n",
        "def evaluate_model(model, loss_type, history, X_test_scaled, y_test_tf, y_test, BATCH_SIZE, GAN_LAMBDA):\n",
        "    print(\"\\nEvaluating on the Test Set...\")\n",
        "\n",
        "    # Evaluate the model using model.evaluate or manual calculation for custom loop\n",
        "    # Calculate metrics manually using predictions for all loss types for consistency\n",
        "    y_pred_logits_test = model.predict(X_test_scaled, batch_size=BATCH_SIZE)\n",
        "    y_pred_probs_test = tf.sigmoid(y_pred_logits_test).numpy().flatten()\n",
        "    y_pred_binary_test = (y_pred_probs_test > 0.5).astype(int)\n",
        "    y_true_test_flat = y_test.values.flatten()\n",
        "\n",
        "    # 1. Get predicted probabilities from model\n",
        "    y_pred_probs = model.predict(X_test_scaled, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # 2. Convert probabilities to class predictions (threshold = 0.5)\n",
        "    y_pred_labels = (y_pred_probs >= 0.5).astype(int)\n",
        "\n",
        "    # 3. Ensure y_test is in correct format (binary integers)\n",
        "    y_true = np.array(y_test_tf).astype(int)\n",
        "\n",
        "    # 4. Calculate metrics\n",
        "    accuracy = round(accuracy_score(y_true, y_pred_labels),2)\n",
        "    precision = round(precision_score(y_true, y_pred_labels, zero_division=0),2)\n",
        "    recall = round(recall_score(y_true, y_pred_labels, zero_division=0),2)\n",
        "    auc_roc = round(roc_auc_score(y_true, y_pred_probs),2)\n",
        "    auc_pr = round(average_precision_score(y_true, y_pred_probs),2)\n",
        "\n",
        "    # Confusion Matrix components\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true_test_flat, y_pred_binary_test, labels=[0, 1]).ravel()\n",
        "\n",
        "    # Specificity (True Negative Rate)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "    # Geometric Mean (G-mean)\n",
        "    current_recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    specificity_gmean = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    g_mean = np.sqrt(current_recall * specificity_gmean) if current_recall >= 0 and specificity_gmean >= 0 else np.nan\n",
        "    g_mean = round(g_mean, 2)\n",
        "\n",
        "\n",
        "    # Balanced Accuracy\n",
        "    bal_accuracy = balanced_accuracy_score(y_true_test_flat, y_pred_binary_test)\n",
        "    bal_accuracy = round(bal_accuracy, 2)\n",
        "\n",
        "    # Kuipers Skill Score (KSS) / True Skill Score (TSS)\n",
        "    kss_tss = current_recall + specificity - 1\n",
        "    kss_tss = round(kss_tss, 2)\n",
        "\n",
        "    # Heidke Skill Score (HSS)\n",
        "    far = false_alarm(tp,tn,fp,fn)\n",
        "    bias = bias_score(tp,tn,fp,fn)\n",
        "    pod = probability_of_detection(tp,tn,fp,fn)\n",
        "    hss= heidke_skill_score(tp,tn,fp,fn)\n",
        "    pss = pierce_skill_score(tp,tn,fp,fn)\n",
        "    f1  =  f1_score(tp,tn,fp,fn)\n",
        "\n",
        "    num_minority_test = np.sum(y_test)\n",
        "    num_majority_test = len(y_test) - num_minority_test # Corrected from num_minority_test\n",
        "\n",
        "    #Combine Keras metrics and manually calculated metrics\n",
        "    test_metrics_dict = {\n",
        "        'Dataset': os.path.basename(current_file_name), # Use the current file name\n",
        "        'Loss_Type': loss_type,\n",
        "        #'Loss': loss, # Loss is not directly comparable across loss functions on the test set\n",
        "        #'Epochs': len(history['loss']) if loss_type not in ['GAN', 'METALEARNING'] else (len(history['gen_loss']) if loss_type == 'GAN' else len(history['meta_val_loss'])), # Get epochs from appropriate history\n",
        "        'Epochs': len(history['loss']) if loss_type not in ['GAN'] else (len(history['gen_loss']) if loss_type == 'GAN' else len(history['meta_val_loss'])), # Get epochs from appropriate history\n",
        "        'Batch_Size': BATCH_SIZE,\n",
        "        'Positive': num_minority_test,\n",
        "        'Negative': num_majority_test,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn,\n",
        "        'Accuracy' : accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'AUC-ROC': auc_roc,\n",
        "        'AUC-PR': auc_pr,\n",
        "        'Specificity': specificity,\n",
        "        'G-Mean': g_mean,\n",
        "        'Balanced_Accuracy': bal_accuracy,\n",
        "        'KSS_TSS': kss_tss,\n",
        "        'HSS': hss,\n",
        "        'PSS': pss,\n",
        "        'FAR': far,\n",
        "        'bias': bias,\n",
        "        'pod': pod,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "\n",
        "    # If the loss type is AMRL, add the learned parameters to the results dictionary\n",
        "    if loss_type == 'AMRL':\n",
        "         # Need to access the loss function object from the training loop\n",
        "         # This requires passing it or retrieving it if it's a global/accessible variable\n",
        "         # For now, assuming loss_function is still available from the training scope\n",
        "         if 'loss_function' in locals() and isinstance(loss_function, AMRLLossTF):\n",
        "            test_metrics_dict['Learned_M_POS'] = loss_function.m1.numpy()\n",
        "            test_metrics_dict['Learned_M_NEG'] = loss_function.m0.numpy()\n",
        "            test_metrics_dict['Learned_LAMBDA_POS'] = loss_function.lambda1.numpy()\n",
        "            test_metrics_dict['Learned_LAMBDA_NEG'] = loss_function.lambda0.numpy()\n",
        "\n",
        "    # If the loss type is PGFL, add the learned alpha and final moving averages\n",
        "    elif loss_type == 'PGFL':\n",
        "         if 'loss_function' in locals() and isinstance(loss_function, PGFLossTF):\n",
        "            test_metrics_dict['Learned_Alpha'] = loss_function.alpha.numpy()\n",
        "            test_metrics_dict['Final_MC0'] = loss_function.mc0.numpy()\n",
        "            test_metrics_dict['Final_MC1'] = loss_function.mc1.numpy()\n",
        "    # If the loss type is GAN, add the GAN_LAMBDA parameter\n",
        "    elif loss_type == 'GAN':\n",
        "         test_metrics_dict['GAN_Lambda'] = GAN_LAMBDA\n",
        "    # If the loss type is METALEARNING, add the final learned minority weight\n",
        "    # elif loss_type == 'METALEARNING':\n",
        "    #      if minority_loss_weight is not None: # Check if the weight was initialized\n",
        "    #         test_metrics_dict['Final_Minority_Weight'] = minority_loss_weight.numpy()\n",
        "\n",
        "\n",
        "    for metric, value in test_metrics_dict.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"{metric}: {value}\")\n",
        "\n",
        "    return test_metrics_dict, history # Return history as well for plotting\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Add 'GAN' to the list of loss functions to compare\n",
        "    LOSS_TYPES_TO_COMPARE = ['AMRL', 'BCE', 'FOCAL', 'CB', 'PGFL', 'GAN']\n",
        "    # LOSS_TYPES_TO_COMPARE = ['METALEARNING', 'BCE'] # Add METALEARNING to the list\n",
        "\n",
        "    # --- Configuration for data loading ---\n",
        "    # Ensure GOOGLE_DRIVE_PATH is set and exists\n",
        "    if 'GOOGLE_DRIVE_PATH' not in globals() or not os.path.exists(GOOGLE_DRIVE_PATH):\n",
        "        # This check should now pass after the previous cell\n",
        "        raise ValueError(\"GOOGLE_DRIVE_PATH not set or does not exist. Please configure it to your Google Drive folder containing XLSX files.\")\n",
        "\n",
        "    print(f\"Scanning for XLSX files in: {GOOGLE_DRIVE_PATH}\")\n",
        "\n",
        "    file_paths_to_process = [os.path.join(GOOGLE_DRIVE_PATH, f) for f in os.listdir(GOOGLE_DRIVE_PATH) if f.endswith('.xlsx')]\n",
        "    # sort the files\n",
        "    file_paths_to_process = sorted(file_paths_to_process, key=lambda x: os.path.basename(x).lower())\n",
        "\n",
        "    if not file_paths_to_process:\n",
        "        print(f\"No XLSX files found in {GOOGLE_DRIVE_PATH}. Please check the path and file extensions.\")\n",
        "        # exit() # Don't exit in a single cell, just print message and continue\n",
        "\n",
        "    # Create directories to save plots and text files within the Google Drive path\n",
        "    plots_save_dir = os.path.join(GOOGLE_DRIVE_PATH, 'training_plots')\n",
        "    os.makedirs(plots_save_dir, exist_ok=True)\n",
        "    print(f\"Plots will be saved to: {plots_save_dir}\")\n",
        "\n",
        "    results_save_dir = os.path.join(GOOGLE_DRIVE_PATH, 'text files')\n",
        "    os.makedirs(results_save_dir, exist_ok=True)\n",
        "    print(f\"Results will be saved to: {results_save_dir}\")\n",
        "\n",
        "\n",
        "    for file_path in file_paths_to_process:\n",
        "        current_file_name = os.path.basename(file_path)\n",
        "        print(f\"\\n############################################################\")\n",
        "        print(f\"Processing Dataset: {current_file_name}\")\n",
        "        print(f\"############################################################\")\n",
        "\n",
        "        # Load data for the current file\n",
        "        df = load_data_from_drive(file_path)\n",
        "        if df is None:\n",
        "            print(f\"Skipping {current_file_name} due to loading error.\")\n",
        "            continue # Skip to the next file\n",
        "\n",
        "        # Define features (X) and target (y)\n",
        "        # Assumes the last column is always the target\n",
        "\n",
        "        # Remove certain columns whihc i think are not relevant\n",
        "        print(df.head())\n",
        "        # FIX: Drop 'Date' column explicitly from features before splitting\n",
        "        df_new = df.drop(['Date', 'Station_Code', 'Cloud_Amount', 'Sunshine', 'Fresh_Snow_WEq', 'Snow_Penetration', 'Snow_Temperature'], axis=1, errors='ignore')\n",
        "\n",
        "        # take only the rows upto 1351 and ignore records from 01 Nov 2023 onwards since occurences very lss after that\n",
        "        df_new = df_new.iloc[:4351, :]\n",
        "        # Drop rows with any NaN values\n",
        "        df_new = df_new.dropna()\n",
        "\n",
        "        # Ensure the target is the last column after dropping\n",
        "        X = df_new.iloc[:, :-1]\n",
        "        y = df_new.iloc[:, -1]\n",
        "\n",
        "\n",
        "        # --- Data Preprocessing and Splitting (for current dataset) ---\n",
        "        print(\"\\nSplitting data into train, validation, and test sets...\")\n",
        "        # Use the processed X and y for splitting\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify = y)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = (0.1/0.8), random_state=42, stratify = y_train)\n",
        "\n",
        "        print(f\"Train set size: {len(X_train)} (Minority: {y_train.sum()})\")\n",
        "        print(f\"Validation set size: {len(X_val)} (Minority: {y_val.sum()})\")\n",
        "        print(f\"Test set size: {len(X_test)} (Minority: {y_test.sum()})\") # Corrected to y_test.sum()\n",
        "\n",
        "\n",
        "        # Collect ratios\n",
        "        ratios_results = []\n",
        "        for name, labels in [(\"Train\", y_train), (\"Validation\", y_val), (\"Test\", y_test)]:\n",
        "          counts, ratio, imbalance_ratio = get_class_ratio(labels.values.flatten()) # Ensure labels are flattened\n",
        "          ratio_str = \", \".join([f\"{cls}: {ratio[cls]:.{2}f}\" for cls in ratio])\n",
        "          ratios_results.append(\n",
        "            f\"{name} set:\\n\"\n",
        "            f\" Counts: {counts.tolist()} (0s={counts[0]}, 1s={counts[1]})\\n\" # Access counts correctly\n",
        "            f\" Ratios: {{{ratio_str}}}\\n\"\n",
        "            f\" Imbalance Ratio (maj:min): {imbalance_ratio}\\n\"\n",
        "            )\n",
        "\n",
        "        # Save to text file\n",
        "        ratios_file_path = os.path.join(results_save_dir, f\"{current_file_name}_class_ratios.txt\")\n",
        "        print(f\"Saving class ratios to: {ratios_file_path}\")\n",
        "        with open(ratios_file_path, \"w\") as f:\n",
        "          for res in ratios_results:\n",
        "            f.write(res + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        # Apply scaler to the numerical features\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        y_train_tf = y_train.values.astype(np.float32).reshape(-1, 1)\n",
        "        y_val_tf = y_val.values.astype(np.float32).reshape(-1, 1)\n",
        "        y_test_tf = y_test.values.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "\n",
        "        # Create TensorFlow Datasets for custom training loop\n",
        "        train_dataset_tf = tf.data.Dataset.from_tensor_slices((X_train_scaled.astype(np.float32), y_train_tf)).batch(BATCH_SIZE).shuffle(buffer_size=len(X_train_scaled))\n",
        "        # Split the validation set further for meta-learning (even if not using meta-learning in this run, keep for consistency)\n",
        "        X_val_inner, X_meta_val, y_val_inner, y_meta_val = train_test_split(\n",
        "            X_val_scaled, y_val_tf, test_size=0.5, random_state=42, stratify=y_val_tf\n",
        "        )\n",
        "        val_dataset_inner = tf.data.Dataset.from_tensor_slices((X_val_inner.astype(np.float32), y_val_inner)).batch(BATCH_SIZE)\n",
        "        meta_val_dataset_tf = tf.data.Dataset.from_tensor_slices((X_meta_val.astype(np.float32), y_meta_val)).batch(BATCH_SIZE)\n",
        "\n",
        "        # test_dataset_tf = tf.data.Dataset.from_tensor_slices((X_test_scaled.astype(np.float32), y_test_tf)).batch(BATCH_SIZE)\n",
        "\n",
        "        # --- Loss Function Parameters (common calculations for current dataset) ---\n",
        "        num_minority_train = np.sum(y_train)\n",
        "        num_majority_train = len(y_train) - num_minority_train\n",
        "\n",
        "\n",
        "        w1_bce_amrl = num_majority_train / (num_minority_train + num_majority_train)\n",
        "        w0_bce_amrl = num_minority_train / (num_minority_train + num_majority_train)\n",
        "\n",
        "        # Parameters for Focal Loss\n",
        "        alpha_focal = num_majority_train / (num_majority_train + num_minority_train) # Corrected denominator\n",
        "        gamma_focal = 2.0\n",
        "\n",
        "        # Parameters for Class Balanced Loss\n",
        "        beta_cb = 0.999\n",
        "\n",
        "        # Parameters for PGFL\n",
        "        gamma_pgfl = 2.0\n",
        "        # Initialize alpha for PGFL using inverse frequency from training data\n",
        "        alpha_init_pgfl = num_majority_train / (num_majority_train + num_minority_train)\n",
        "\n",
        "        # Parameters for GAN Loss\n",
        "        GAN_LAMBDA = 0.1 # Weighting factor for the adversarial loss component in the generator's total loss\n",
        "        # For the GAN, we'll use BCE as the base classification loss for the generator\n",
        "\n",
        "        # Parameters for Meta-Learning\n",
        "        META_LEARNING_RATE = 0.01 # Learning rate for the meta-optimizer\n",
        "        INNER_EPOCHS = 1 # Number of inner loop epochs per outer loop epoch\n",
        "        # The base loss function for the inner loop (model training) and meta-validation loss\n",
        "        BASE_CLASSIFICATION_LOSS_FN = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "        # Calculate input_dim from the scaled training data shape\n",
        "        input_dim = X_train_scaled.shape[1]\n",
        "        print(f\"Input dimension for the model: {input_dim}\")\n",
        "\n",
        "        loss_results_for_file = [] # List to store results for each loss function for the current file\n",
        "\n",
        "        for loss_type in LOSS_TYPES_TO_COMPARE:\n",
        "            print(f\"\\n--------------------------------------------------------\")\n",
        "            print(f\"Training {current_file_name} with {loss_type} Loss\")\n",
        "            print(f\"--------------------------------------------------------\")\n",
        "\n",
        "            # Re-initialize the model(s) and optimizers for each loss function to ensure a fresh start\n",
        "            model = SimpleMLP_TF(input_dim)\n",
        "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # Optimizer for the main model (Generator)\n",
        "\n",
        "            discriminator_model = None # Discriminator is only needed for GAN loss\n",
        "            discriminator_optimizer = None # Discriminator optimizer is only needed for GAN loss\n",
        "\n",
        "            minority_loss_weight = None # Trainable weight for Meta-Learning\n",
        "            meta_optimizer = None # Optimizer for Meta-Learning weight\n",
        "\n",
        "            loss_function = None # Classification loss function (used directly or as base for GAN/Meta-Learning)\n",
        "            history = None # Initialize history variable\n",
        "\n",
        "\n",
        "            if loss_type == 'AMRL':\n",
        "                print(\"Margin Loss Parameters (Initial Values):\")\n",
        "                print(f\"  BCE Weights: w1_bce (minority) = {w1_bce_amrl:.4f}, w0_bce (majority) = {w0_bce_amrl:.4f}\")\n",
        "                print(f\"  Margins: m1 (pos) = {M_POS_INIT}, m0 (neg) = {M_NEG_INIT}\")\n",
        "                print(f\"  Lambdas: lambda1 (pos) = {LAMBDA_POS_INIT}, lambda0 (neg) = {LAMBDA_NEG_INIT}\")\n",
        "                print(f\"  Betas: beta1 (pos) = {BETA_POS_INIT}, beta0 = {BETA_NEG_INIT}\")\n",
        "                loss_function = AMRLLossTF(w1 = w1_bce_amrl, w0 = w0_bce_amrl, m1_init = M_POS_INIT, m0_init = M_NEG_INIT,\n",
        "                                          lambda1_init=LAMBDA_POS_INIT, lambda0_init = LAMBDA_NEG_INIT,\n",
        "                                          beta1 = BETA_POS_INIT, beta0 = BETA_NEG_INIT)\n",
        "\n",
        "                print(\"\\nStarting custom training loop for AMRL...\")\n",
        "                early_stopping_callback = EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, min_delta=MIN_DELTA, restore_best_weights=True)\n",
        "                history = custom_train_loop(model, loss_function, optimizer, train_dataset_tf, val_dataset_inner, NUM_EPOCHS, early_stopping_callback, CLIP_NORM) # Use val_dataset_inner for validation\n",
        "                print(\"Custom training loop finished.\")\n",
        "\n",
        "            elif loss_type == 'PGFL':\n",
        "                print(\"PGFL Loss Parameters (Initial Values):\")\n",
        "                print(f\"  Gamma: {gamma_pgfl:.4f}\")\n",
        "                print(f\"  Initial Alpha (Minority Weight): {alpha_init_pgfl:.4f}\")\n",
        "                loss_function = PGFLossTF(num_majority=num_majority_train, num_minority=num_minority_train,\n",
        "                                          gamma=gamma_pgfl, alpha_init=alpha_init_pgfl)\n",
        "\n",
        "\n",
        "                print(\"\\nStarting custom training loop for PGFL...\")\n",
        "                early_stopping_callback = EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, min_delta=MIN_DELTA, restore_best_weights=True)\n",
        "                history = custom_train_loop_pgfl(model, loss_function, optimizer, train_dataset_tf, val_dataset_inner, NUM_EPOCHS, early_stopping_callback, CLIP_NORM) # Use val_dataset_inner for validation\n",
        "                print(\"Custom training loop finished.\")\n",
        "\n",
        "            elif loss_type == 'GAN':\n",
        "                print(\"GAN Loss Parameters:\")\n",
        "                print(f\"  GAN Lambda (Adversarial Loss Weight): {GAN_LAMBDA:.4f}\")\n",
        "                classification_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "                input_dim_features = X_train_scaled.shape[1]\n",
        "                discriminator_model = Discriminator(input_dim_X=input_dim_features, input_dim_Y=1)\n",
        "                discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "                print(\"\\nStarting custom training loop for GAN...\")\n",
        "                early_stopping_callback = EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, min_delta=MIN_DELTA, restore_best_weights=True)\n",
        "                history = custom_train_loop_gan(model, discriminator_model, optimizer, discriminator_optimizer,\n",
        "                                                classification_loss_fn, train_dataset_tf, val_dataset_inner, # Use val_dataset_inner for validation\n",
        "                                                NUM_EPOCHS, early_stopping_callback, CLIP_NORM, GAN_LAMBDA)\n",
        "                print(\"Custom training loop finished.\")\n",
        "\n",
        "\n",
        "\n",
        "            else: # Use model.compile and model.fit for other loss functions (BCE, FOCAL, CB)\n",
        "                metrics_list = [\n",
        "                    BinaryAccuracy(name = 'accuracy', threshold = 0.5),\n",
        "                    Precision(name = 'precision', thresholds = 0.5),\n",
        "                    Recall(name = 'recall', thresholds = 0.5),\n",
        "                    AUC(name = 'auc_roc'),\n",
        "                    AUC(curve = 'PR', name ='auc_pr')\n",
        "                ]\n",
        "\n",
        "                if loss_type == 'BCE':\n",
        "                    print(\"Standard Binary Crossentropy Loss\")\n",
        "                    loss_function = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
        "                elif loss_type == 'FOCAL':\n",
        "                    print(f\"Focal Loss Parameters: alpha={alpha_focal:.4f}, gamma={gamma_focal:.4f}\")\n",
        "                    loss_function = FocalLossTF(alpha = alpha_focal, gamma = gamma_focal)\n",
        "                elif loss_type == 'CB':\n",
        "                    print(f\"Class Balanced Loss Parameters: beta={beta_cb:.4f}\")\n",
        "                    loss_function = ClassBalancedLossTF(num_majority = num_majority_train, num_minority = num_minority_train, beta = beta_cb)\n",
        "                else:\n",
        "                    raise ValueError(f\"Invalid LOSS_TYPE: {loss_type}. Choose from 'AMRL', 'BCE', 'FOCAL', 'CB', 'PGFL', 'GAN'.\")\n",
        "\n",
        "\n",
        "                # Compile the model using the selected loss function and metrics\n",
        "                model.compile(optimizer=optimizer, # Use the same optimizer\n",
        "                              loss=loss_function,\n",
        "                              metrics=metrics_list)\n",
        "\n",
        "                # Define Early Stopping callback for model.fit\n",
        "                early_stopping_callback = EarlyStopping(monitor='val_loss',\n",
        "                                               patience=EARLY_STOPPING_PATIENCE,\n",
        "                                               min_delta=MIN_DELTA,\n",
        "                                               restore_best_weights=True,\n",
        "                                               verbose=1)\n",
        "\n",
        "                print(\"\\nStarting model.fit training...\")\n",
        "                history = model.fit(X_train_scaled, y_train_tf,\n",
        "                                    epochs=NUM_EPOCHS,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    validation_data=(X_val_scaled, y_val_tf), # Use the original val set for model.fit\n",
        "                                    callbacks=[early_stopping_callback],\n",
        "                                    verbose=1)\n",
        "                history = history.history\n",
        "\n",
        "                print(\"model.fit training finished.\")\n",
        "\n",
        "            # --- Plotting Training History ---\n",
        "            if history: # Check if history is not None\n",
        "                print(\"\\nPlotting training history...\")\n",
        "                if loss_type == 'GAN':\n",
        "                     # Plot GAN specific losses\n",
        "                    gan_history_to_plot = {k: history[k] for k in ['gen_loss', 'disc_loss', 'gen_clf_loss', 'gen_adv_loss'] if k in history}\n",
        "                    plot_training_history(gan_history_to_plot, current_file_name, f'{loss_type}_Losses', plots_save_dir)\n",
        "\n",
        "                    # Plot Generator's classification metrics (using 'accuracy', etc keys which are for generator)\n",
        "                    gen_metric_history_to_plot = {k: history[k] for k in ['accuracy', 'precision', 'recall', 'auc_roc', 'auc_pr',\n",
        "                                                                      'val_accuracy', 'val_precision', 'val_recall', 'val_auc_roc', 'val_auc_pr',\n",
        "                                                                      'val_loss'] if k in history\n",
        "                                                                      }\n",
        "                    # Rename 'val_loss' to 'val_gen_clf_loss' for clarity in plot title/labels if it exists\n",
        "                    if 'val_loss' in gen_metric_history_to_plot:\n",
        "                        gen_metric_history_to_plot['val_gen_clf_loss'] = gen_metric_history_to_plot.pop('val_loss')\n",
        "\n",
        "                    plot_training_history(gen_metric_history_to_plot, current_file_name, f'{loss_type}_Generator_Metrics', plots_save_dir)\n",
        "\n",
        "\n",
        "                else:\n",
        "                     # For other losses, plot standard metrics including validation loss\n",
        "                    plot_history = {k: history[k] for k in history if k in ['loss', 'accuracy', 'precision', 'recall', 'auc_roc', 'auc_pr',\n",
        "                                                                            'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_auc_roc', 'val_auc_pr']}\n",
        "                    plot_training_history(plot_history, current_file_name, loss_type, plots_save_dir)\n",
        "\n",
        "\n",
        "            print(\"\\nEvaluating on the Test Set...\")\n",
        "\n",
        "            print(\"Train class distribution:\", np.bincount(y_train.values.flatten()))\n",
        "            print(\"Val class distribution:\", np.bincount(y_val.values.flatten()))\n",
        "            print(\"Test class distribution:\", np.bincount(y_test.values.flatten()))\n",
        "\n",
        "\n",
        "            # Evaluate the model using model.evaluate or manual calculation for custom loop\n",
        "            # Calculate metrics manually using predictions for all loss types for consistency\n",
        "            y_pred_logits_test = model.predict(X_test_scaled, batch_size=BATCH_SIZE)\n",
        "            y_pred_probs_test = tf.sigmoid(y_pred_logits_test).numpy().flatten()\n",
        "            y_pred_binary_test = (y_pred_probs_test > 0.5).astype(int)\n",
        "            y_true_test_flat = y_test.values.flatten()\n",
        "\n",
        "            # 1. Get predicted probabilities from model\n",
        "            y_pred_probs = model.predict(X_test_scaled, batch_size=BATCH_SIZE)\n",
        "\n",
        "            # 2. Convert probabilities to class predictions (threshold = 0.5)\n",
        "            y_pred_labels = (y_pred_probs >= 0.5).astype(int)\n",
        "\n",
        "            # 3. Ensure y_test is in correct format (binary integers)\n",
        "            y_true = np.array(y_test_tf).astype(int)\n",
        "\n",
        "            # 4. Calculate metrics\n",
        "            accuracy = round(accuracy_score(y_true, y_pred_labels),2)\n",
        "            precision = round(precision_score(y_true, y_pred_labels, zero_division=0),2)\n",
        "            recall = round(recall_score(y_true, y_pred_labels, zero_division=0),2)\n",
        "            auc_roc = round(roc_auc_score(y_true, y_pred_probs),2)\n",
        "            auc_pr = round(average_precision_score(y_true, y_pred_probs),2)\n",
        "\n",
        "            # Confusion Matrix components\n",
        "            tn, fp, fn, tp = confusion_matrix(y_true_test_flat, y_pred_binary_test, labels=[0, 1]).ravel()\n",
        "\n",
        "            # Specificity (True Negative Rate)\n",
        "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "            # Geometric Mean (G-mean)\n",
        "            current_recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "            specificity_gmean = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "            g_mean = np.sqrt(current_recall * specificity_gmean) if current_recall >= 0 and specificity_gmean >= 0 else np.nan\n",
        "            g_mean = round(g_mean, 2)\n",
        "\n",
        "\n",
        "            # Balanced Accuracy\n",
        "            bal_accuracy = balanced_accuracy_score(y_true_test_flat, y_pred_binary_test)\n",
        "            bal_accuracy = round(bal_accuracy, 2)\n",
        "\n",
        "            # Kuipers Skill Score (KSS) / True Skill Score (TSS)\n",
        "            kss_tss = current_recall + specificity - 1\n",
        "            kss_tss = round(kss_tss, 2)\n",
        "\n",
        "            # Heidke Skill Score (HSS)\n",
        "            far = false_alarm(tp,tn,fp,fn)\n",
        "            bias = bias_score(tp,tn,fp,fn)\n",
        "            pod = probability_of_detection(tp,tn,fp,fn)\n",
        "            hss= heidke_skill_score(tp,tn,fp,fn)\n",
        "            pss = pierce_skill_score(tp,tn,fp,fn)\n",
        "            f1  =  f1_score(tp,tn,fp,fn)\n",
        "\n",
        "            num_minority_test = np.sum(y_test)\n",
        "            num_majority_test = len(y_test) - num_minority_test\n",
        "\n",
        "            #Combine Keras metrics and manually calculated metrics\n",
        "            test_metrics_dict = {\n",
        "                'Dataset': current_file_name,\n",
        "                'Loss_Type': loss_type,\n",
        "                #'Loss': loss, # Loss is not directly comparable across loss functions on the test set\n",
        "                'Epochs': len(history['loss']) if loss_type not in ['GAN'] else (len(history['gen_loss']) if 'gen_loss' in history else 0), # Get epochs from appropriate history, handle empty history\n",
        "                'Batch_Size': BATCH_SIZE,\n",
        "                'Positive': num_minority_test,\n",
        "                'Negative': num_majority_test,\n",
        "                'TP': tp,\n",
        "                'TN': tn,\n",
        "                'FP': fp,\n",
        "                'FN': fn,\n",
        "                'Accuracy' : accuracy,\n",
        "                'Precision': precision,\n",
        "                'Recall': recall,\n",
        "                'AUC-ROC': auc_roc,\n",
        "                'AUC-PR': auc_pr,\n",
        "                'Specificity': specificity,\n",
        "                'G-Mean': g_mean,\n",
        "                'Balanced_Accuracy': bal_accuracy,\n",
        "                'KSS_TSS': kss_tss,\n",
        "                'HSS': hss,\n",
        "                'PSS': pss,\n",
        "                'FAR': far,\n",
        "                'bias': bias,\n",
        "                'pod': pod,\n",
        "                'f1': f1\n",
        "            }\n",
        "\n",
        "\n",
        "            # If the loss type is AMRL, add the learned parameters to the results dictionary\n",
        "            if loss_type == 'AMRL':\n",
        "                 if isinstance(loss_function, AMRLLossTF):\n",
        "                    test_metrics_dict['Learned_M_POS'] = loss_function.m1.numpy()\n",
        "                    test_metrics_dict['Learned_M_NEG'] = loss_function.m0.numpy()\n",
        "                    test_metrics_dict['Learned_LAMBDA_POS'] = loss_function.lambda1.numpy()\n",
        "                    test_metrics_dict['Learned_LAMBDA_NEG'] = loss_function.lambda0.numpy()\n",
        "\n",
        "            # If the loss type is PGFL, add the learned alpha and final moving averages\n",
        "            elif loss_type == 'PGFL':\n",
        "                 if isinstance(loss_function, PGFLossTF):\n",
        "                    test_metrics_dict['Learned_Alpha'] = loss_function.alpha.numpy()\n",
        "                    test_metrics_dict['Final_MC0'] = loss_function.mc0.numpy()\n",
        "                    test_metrics_dict['Final_MC1'] = loss_function.mc1.numpy()\n",
        "            # If the loss type is GAN, add the GAN_LAMBDA parameter\n",
        "            elif loss_type == 'GAN':\n",
        "                 test_metrics_dict['GAN_Lambda'] = GAN_LAMBDA\n",
        "\n",
        "\n",
        "            for metric, value in test_metrics_dict.items():\n",
        "                if isinstance(value, float):\n",
        "                    print(f\"{metric}: {value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: {value}\")\n",
        "\n",
        "            # --- Consolidate and Save All Results ---\n",
        "            # Save this loss result in the list\n",
        "            loss_results_for_file.append(test_metrics_dict.copy())\n",
        "\n",
        "        # --- Save all loss results for the current file ---\n",
        "        file_results_df = pd.DataFrame(loss_results_for_file)\n",
        "        output_filename = f\"{current_file_name}_all_losses.xlsx\"\n",
        "        results_save_dir = os.path.join(GOOGLE_DRIVE_PATH, 'text files')\n",
        "        os.makedirs(results_save_dir, exist_ok=True)\n",
        "        print(f\"Results will be saved to: {results_save_dir}\")\n",
        "        output_filepath = os.path.join(results_save_dir, output_filename) # Use GOOGLE_DRIVE_PATH for saving\n",
        "        file_results_df.to_excel(output_filepath, index=False)\n",
        "        # output_filepath = os.path.join(GOOGLE_DRIVE_PATH, output_filename)\n",
        "        # file_results_df.to_csv(output_filepath, index=False)\n",
        "\n",
        "        print(f\"\\nResults for {current_file_name} saved to: {output_filepath}\")\n",
        "        print(\"\\nComprehensive Comparison Summary for this file:\")\n",
        "        print(file_results_df.round(4).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0e20c8e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Assuming the results files are saved in the 'text files' directory within GOOGLE_DRIVE_PATH\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "GOOGLE_DRIVE_PATH = '/content/drive/MyDrive/1. Trial/'\n",
        "results_save_dir = os.path.join(GOOGLE_DRIVE_PATH, 'text files')\n",
        "\n",
        "# List all the result files in the directory\n",
        "result_files = [f for f in os.listdir(results_save_dir) if f.endswith('_all_losses.xlsx')]\n",
        "\n",
        "if not result_files:\n",
        "    print(f\"No result files found in {results_save_dir}. Please ensure the main execution block ran successfully.\")\n",
        "else:\n",
        "    all_results_list = []\n",
        "    for file_name in result_files:\n",
        "        file_path = os.path.join(results_save_dir, file_name)\n",
        "        try:\n",
        "            df_results = pd.read_excel(file_path)\n",
        "            all_results_list.append(df_results)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {file_path}: {e}\")\n",
        "\n",
        "    if all_results_list:\n",
        "        # Concatenate all results into a single DataFrame\n",
        "        all_results_df = pd.concat(all_results_list, ignore_index=True)\n",
        "\n",
        "        print(\"\\n--- Performance Summary Across Datasets and Loss Functions ---\")\n",
        "\n",
        "        # Group by Loss_Type and calculate mean for key metrics\n",
        "        # Select key metrics for summary\n",
        "        summary_metrics = ['Accuracy', 'Precision', 'Recall', 'AUC-ROC', 'AUC-PR',\n",
        "                           'Specificity', 'G-Mean', 'Balanced_Accuracy', 'KSS_TSS', 'HSS', 'PSS', 'FAR', 'bias', 'pod', 'f1']\n",
        "\n",
        "        # Ensure only existing columns are included in summary_metrics\n",
        "        summary_metrics = [metric for metric in summary_metrics if metric in all_results_df.columns]\n",
        "\n",
        "\n",
        "        performance_summary = all_results_df.groupby('Loss_Type')[summary_metrics].mean().round(4)\n",
        "\n",
        "        print(\"Average Performance Metrics per Loss Function (averaged across datasets):\")\n",
        "        display(performance_summary)\n",
        "\n",
        "        # Optional: Also show metrics per dataset per loss function if needed\n",
        "        # print(\"\\nPerformance Metrics per Dataset per Loss Function:\")\n",
        "        # display(all_results_df[['Dataset', 'Loss_Type'] + summary_metrics].round(4))\n",
        "\n",
        "    else:\n",
        "        print(\"No data available to summarize after attempting to read result files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed560fd3"
      },
      "source": [
        "# Task\n",
        "Implement a new loss function and training strategy based on meta-learning reweighting and fine-tuning for extreme samples, and integrate it into the existing code for comparison with other loss functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48c06d14"
      },
      "source": [
        "## Define the meta-learning reweighting component\n",
        "\n",
        "### Subtask:\n",
        "Implement a mechanism to learn the weights for the loss function using a meta-learning approach. This will likely involve an outer loop that optimizes the weighting parameters based on the model's performance on a small validation set or a specific metric, and an inner loop that trains the main model with the current weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "333de5dc"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a separate small \"meta-validation\" dataset and implement a mechanism to define and update sample weights using trainable `tf.Variable`s.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bc3540f"
      },
      "outputs": [],
      "source": [
        "# Step 1: Define a separate small \"meta-validation\" dataset\n",
        "# We can split the existing validation set further. Let's use 50% of the original validation set for meta-validation.\n",
        "# The remaining 50% will be the standard validation set used in the inner loop.\n",
        "\n",
        "# Assuming X_val_scaled and y_val_tf from previous steps are available\n",
        "# Split the validation set into validation and meta-validation sets\n",
        "X_val_inner, X_meta_val, y_val_inner, y_meta_val = train_test_split(\n",
        "    X_val_scaled, y_val_tf, test_size=0.5, random_state=42, stratify=y_val_tf\n",
        ")\n",
        "\n",
        "# Create TensorFlow Datasets for inner validation and meta-validation\n",
        "val_dataset_inner = tf.data.Dataset.from_tensor_slices((X_val_inner.astype(np.float32), y_val_inner)).batch(BATCH_SIZE)\n",
        "meta_val_dataset_tf = tf.data.Dataset.from_tensor_slices((X_meta_val.astype(np.float32), y_meta_val)).batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "# Step 2: Implement a mechanism to define and update sample weights\n",
        "# We'll use trainable tf.Variables for sample weights.\n",
        "# A simple approach is to have a single trainable scalar weight that gets applied to the loss\n",
        "# of the minority class samples in the inner loop, or perhaps a weight per class.\n",
        "# Let's start with a simple trainable scalar weight applied to the minority class loss.\n",
        "\n",
        "# Initialize a trainable weight for the minority class.\n",
        "# This weight will be learned by the meta-learning process.\n",
        "# Start with a value of 1.0, meaning equal weighting initially (like standard BCE).\n",
        "# We can also initialize it based on inverse class frequency or other heuristics.\n",
        "# Let's initialize it to reflect the imbalance ratio slightly biased towards minority.\n",
        "initial_minority_weight = float(num_majority_train / num_minority_train) # Using training set ratio for initial weight\n",
        "\n",
        "# We can make this weight trainable. Let's call it `minority_loss_weight`.\n",
        "# This weight will be updated in the outer loop.\n",
        "minority_loss_weight = tf.Variable(initial_minority_weight, dtype=tf.float32, trainable=True, name=\"minority_loss_weight\")\n",
        "\n",
        "print(f\"Initial minority loss weight: {minority_loss_weight.numpy():.4f}\")\n",
        "\n",
        "# We also need a way to apply this weight within the inner loop's loss calculation.\n",
        "# This will require modifying the base classification loss function or the custom train step.\n",
        "# Let's plan to apply this weight in the inner training step.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}